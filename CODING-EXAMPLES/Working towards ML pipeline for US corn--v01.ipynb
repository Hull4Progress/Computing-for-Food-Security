{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d62abd29",
   "metadata": {},
   "source": [
    "## <span style=color:blue>This notebook illustrates how to extract ag data from USDS NASS, and weather data from NASAPOWER   </span>\n",
    "\n",
    "### <span style=color:blue>This notebook is very preliminary with a lot of corner cutting; plan to improve it in coming days... </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "748db334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This useful if I want to give unique names to directories or files\n",
    "import datetime\n",
    "def curr_timestamp():\n",
    "    current_datetime = datetime.datetime.now()\n",
    "    formatted_datetime = current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    return formatted_datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081bcb69",
   "metadata": {},
   "source": [
    "### <span style=color:blue> Accessing USDA NASS, following code from https://towardsdatascience.com/harvest-and-analyze-agricultural-data-with-the-usda-nass-api-python-and-tableau-a6af374b8138.  In first cell below we define a class for interacting with the NASS QuickStats API, and in second cell we illustrate how to invoke that class </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec026614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://towardsdatascience.com/harvest-and-analyze-agricultural-data-with-the-usda-nass-api-python-and-tableau-a6af374b8138\n",
    "# with edits\n",
    "\n",
    "#   Name:           c_usda_quick_stats.py\n",
    "#   Author:         Randy Runtsch\n",
    "#   Date:           March 29, 2022\n",
    "#   Project:        Query USDA QuickStats API\n",
    "#   Author:         Randall P. Runtsch\n",
    "#\n",
    "#   Description:    Query the USDA QuickStats api_GET API with a specified set of \n",
    "#                   parameters. Write the retrieved data, in CSV format, to a file.\n",
    "#\n",
    "#   See Quick Stats (NASS) API user guide:  https://quickstats.nass.usda.gov/api\n",
    "#   Request a QuickStats API key here:      https://quickstats.nass.usda.gov/api#param_define\n",
    "#\n",
    "#   Attribution: This product uses the NASS API but is not endorsed or certified by NASS.\n",
    "#\n",
    "#   Changes\n",
    "#\n",
    "\n",
    "import urllib.request\n",
    "from requests.utils import requote_uri\n",
    "import requests\n",
    "\n",
    "# One has to get a NASS API key - please get your own\n",
    "my_NASS_API_key = '8932BB3A-66B1-3140-8FCF-9EF701D75C7B'\n",
    "\n",
    "class c_usda_quick_stats:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # Set the USDA QuickStats API key, API base URL, and output file path where CSV files will be written. \n",
    "\n",
    "        # self.api_key = 'PASTE_YOUR_API_KEY_HERE'\n",
    "        self.api_key = my_NASS_API_key\n",
    "\n",
    "        self.base_url_api_get = 'http://quickstats.nass.usda.gov/api/api_GET/?key=' + self.api_key + '&'\n",
    "\n",
    "        # self.output_file_path = r'c:\\\\usda_quickstats_files\\\\'\n",
    "        self.output_file_path = '/Users/rick/AG-CODE--v03/USDA-NASS--v01/OUTPUTS/'\n",
    "\n",
    "    def get_data(self, parameters, file_name):\n",
    "\n",
    "        # Call the api_GET api with the specified parameters. \n",
    "        # Write the CSV data to the specified output file.\n",
    "\n",
    "        # Create the full URL and retrieve the data from the Quick Stats server.\n",
    "        \n",
    "        full_url = self.base_url_api_get + parameters\n",
    "        \n",
    "        print(full_url)\n",
    "        try:\n",
    "            s_result = urllib.request.urlopen(full_url)\n",
    "            # print(type(s_result))\n",
    "            print(s_result.status, s_result.reason)\n",
    "            # print(s_result.status_code)\n",
    "            s_text = s_result.read().decode('utf-8')\n",
    "\n",
    "            # Create the output file and write the CSV data records to the file.\n",
    "\n",
    "            s_file_name = self.output_file_path + file_name + \".csv\"\n",
    "            o_file = open(s_file_name, \"w\", encoding=\"utf8\")\n",
    "            o_file.write(s_text)\n",
    "            o_file.close()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"An error occurred while fetching the data: {e}\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Failed to parse the response data: {e}\")\n",
    "        except:\n",
    "            print(f\"Failed because of unknown exception; perhaps the USDA NASS site is down\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da48f5fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://quickstats.nass.usda.gov/api/api_GET/?key=8932BB3A-66B1-3140-8FCF-9EF701D75C7B&source_desc=SURVEY&sector_desc%3DFARMS%20%26%20LANDS%20%26%20ASSETS&commodity_desc%3DFARM%20OPERATIONS&statisticcat_desc%3DAREA%20OPERATED&unit_desc=ACRES&freq_desc=ANNUAL&reference_period_desc=YEAR&year__GE=1997&agg_level_desc=NATIONAL&state_name%3DUS%20TOTAL&format=CSV\n",
      "<class 'http.client.HTTPResponse'>\n",
      "200 OK\n"
     ]
    }
   ],
   "source": [
    "# from https://towardsdatascience.com/harvest-and-analyze-agricultural-data-with-the-usda-nass-api-python-and-tableau-a6af374b8138\n",
    "# with edits\n",
    "\n",
    "#   Date:           March 29, 2022\n",
    "#   Project:        Program controller to query USDA QuickStats API\n",
    "#   Author:         Randall P. Runtsch\n",
    "#\n",
    "#   Description:    Create an instance of the c_usda_quick_stats class. Call it with\n",
    "#                   the desired search parameter and output file name.\n",
    "#\n",
    "#   Attribution: This product uses the NASS API but is not endorsed or certified by NASS.\n",
    "#\n",
    "#   Changes\n",
    "#\n",
    "\n",
    "import sys\n",
    "\n",
    "# sys.path.append('/Users/rick/AG-CODE--v03/USDA-NASS--v01/')\n",
    "# from c_usda_quick_stats import c_usda_quick_stats\n",
    "import urllib.parse\n",
    "\n",
    "# Create an instance of the c_usda_quick_stats class. Call it with search parameters\n",
    "# and the output file to write the returned CSV data into.\n",
    "\n",
    "\n",
    "\n",
    "# the QuickStats site is very senstivite to how the full URL is built up.\n",
    "# For example, the following spec for the parameters works\n",
    "# But if you replace the line \"'&unit_desc=ACRES' + \\\" with\n",
    "# the line \"'&' + urllib.parse.quote('unit_desc-ACRES')\"\n",
    "# then the site responds saying that you have exceeded the 50,000 record limit for one query\n",
    "\n",
    "parameters =    'source_desc=SURVEY' +  \\\n",
    "                '&' + urllib.parse.quote('sector_desc=FARMS & LANDS & ASSETS') + \\\n",
    "                '&' + urllib.parse.quote('commodity_desc=FARM OPERATIONS') + \\\n",
    "                '&' + urllib.parse.quote('statisticcat_desc=AREA OPERATED') + \\\n",
    "                '&unit_desc=ACRES' + \\\n",
    "                '&freq_desc=ANNUAL' + \\\n",
    "                '&reference_period_desc=YEAR' + \\\n",
    "                '&year__GE=1997' + \\\n",
    "                '&agg_level_desc=NATIONAL' + \\\n",
    "                '&' + urllib.parse.quote('state_name=US TOTAL') + \\\n",
    "                '&format=CSV'\n",
    "\n",
    "stats = c_usda_quick_stats()\n",
    "\n",
    "# Including curr_timestamp() into file name to keep outputs separated during development/exploration\n",
    "s_json = stats.get_data(parameters, 'national_farm_survey_acres_ge_1997_' + curr_timestamp())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04fb041",
   "metadata": {},
   "source": [
    "###  <span style=color:blue>Now obtaining NASAPOWER data for one point within each county of Indiana (should do it for more states!) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6145b3e1",
   "metadata": {},
   "source": [
    "<span style=color:blue>First, I got a list of all counties in Indiana, and then use geopy to get lat/lon points for each county.  (I cheated and asked ChatGPT for the list of counties; really I should have accessed the list using geopy -- will do that in a next iteration)    </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb7701fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to: /Users/rick/AG-CODE--v03/ML/county_lat_long.csv\n"
     ]
    }
   ],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "import pandas as pd\n",
    "\n",
    "working_dir = '/Users/rick/AG-CODE--v03/ML/'\n",
    "target_file = 'county_lat_long.csv'\n",
    "\n",
    "\n",
    "# List of Indiana counties\n",
    "counties = [\n",
    "    \"Adams\", \"Allen\", \"Bartholomew\", \"Benton\", \"Blackford\", \"Boone\", \"Brown\", \"Carroll\",\n",
    "    \"Cass\", \"Clark\", \"Clay\", \"Clinton\", \"Crawford\", \"Daviess\", \"Dearborn\", \"Decatur\",\n",
    "    \"DeKalb\", \"Delaware\", \"Dubois\", \"Elkhart\", \"Fayette\", \"Floyd\", \"Fountain\", \"Franklin\",\n",
    "    \"Fulton\", \"Gibson\", \"Grant\", \"Greene\", \"Hamilton\", \"Hancock\", \"Harrison\", \"Hendricks\",\n",
    "    \"Henry\", \"Howard\", \"Huntington\", \"Jackson\", \"Jasper\", \"Jay\", \"Jefferson\", \"Jennings\",\n",
    "    \"Johnson\", \"Knox\", \"Kosciusko\", \"LaGrange\", \"Lake\", \"LaPorte\", \"Lawrence\", \"Madison\",\n",
    "    \"Marion\", \"Marshall\", \"Martin\", \"Miami\", \"Monroe\", \"Montgomery\", \"Morgan\", \"Newton\",\n",
    "    \"Noble\", \"Ohio\", \"Orange\", \"Owen\", \"Parke\", \"Perry\", \"Pike\", \"Porter\", \"Posey\", \"Pulaski\",\n",
    "    \"Putnam\", \"Randolph\", \"Ripley\", \"Rush\", \"St. Joseph\", \"Scott\", \"Shelby\", \"Spencer\", \"Starke\",\n",
    "    \"Steuben\", \"Sullivan\", \"Switzerland\", \"Tippecanoe\", \"Tipton\", \"Union\", \"Vanderburgh\",\n",
    "    \"Vermillion\", \"Vigo\", \"Wabash\", \"Warren\", \"Warrick\", \"Washington\", \"Wayne\", \"Wells\",\n",
    "    \"White\", \"Whitley\"\n",
    "]\n",
    "\n",
    "# Geocoding function to retrieve coordinates for a county\n",
    "def geocode_county(county):\n",
    "    geolocator = Nominatim(user_agent=\"county_geocoder\")\n",
    "    location = geolocator.geocode(county + \", Indiana, USA\")\n",
    "    if location:\n",
    "        return location.latitude, location.longitude\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Create a DataFrame to store the county data\n",
    "df = pd.DataFrame(counties, columns=[\"County\"])\n",
    "df[\"Latitude\"], df[\"Longitude\"] = zip(*df[\"County\"].map(geocode_county))\n",
    "df['State'] = 'Indiana'\n",
    "\n",
    "# Save the data to a CSV file\n",
    "save_path = working_dir + target_file  # Replace with the desired save path\n",
    "df.to_csv(save_path, index=False)\n",
    "print(f\"Data saved to: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f4f624b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        County   Latitude  Longitude    State\n",
      "0        Adams  40.737167 -84.934730  Indiana\n",
      "1        Allen  41.097557 -85.056208  Indiana\n",
      "2  Bartholomew  39.191416 -85.820460  Indiana\n",
      "3       Benton  40.603428 -87.323516  Indiana\n",
      "4    Blackford  40.469283 -85.330553  Indiana\n"
     ]
    }
   ],
   "source": [
    "# looking at the contents of the csv\n",
    "\n",
    "working_dir = '/Users/rick/AG-CODE--v03/ml/'\n",
    "filename = 'county_lat_long.csv'\n",
    "\n",
    "df_ind_cty = pd.read_csv(working_dir + filename)\n",
    "print(df_ind_cty.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab447f2",
   "metadata": {},
   "source": [
    "## <span style=color:blue>Next two cells illustrate how to obtain NASA POWER weather data for (the lat/lon points inside) the counties in Indiana.   </span>\n",
    "\n",
    "<span style=color:blue>The corn growing season is from April to October, so restricting data retrieval to those months.\n",
    "\n",
    "<span style=color:blue>Note: After experiencing the nuances of the USDA NASS API, I am conservatively building up the URL for accessing NASA POWER, rather than using the requests command.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc54bdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up a URL template for making requests to NASA POWER\n",
    "\n",
    "# growing season from April to October\n",
    "\n",
    "import json\n",
    "\n",
    "working_dir = '/Users/rick/AG-CODE--v03/ML/'\n",
    "county_file = 'county_lat_long.csv'\n",
    "\n",
    "dfcty = pd.read_csv(working_dir + county_file)\n",
    "# print(dfcty.head())\n",
    "\n",
    "# see https://gist.github.com/abelcallejo/d68e70f43ffa1c8c9f6b5e93010704b8\n",
    "#   for available parameters\n",
    "weather_params = ['T2M_MAX','T2M_MIN', 'PRECTOTCORR', 'GWETROOT', 'EVPTRNS', 'ALLSKY_SFC_PAR_TOT']\n",
    "'''\n",
    "   T2M_MAX: The maximum hourly air (dry bulb) temperature at 2 meters above the surface of the \n",
    "             earth in the period of interest.\n",
    "   T2M_MIN: The minimum hourly air (dry bulb) temperature at 2 meters above the surface of the \n",
    "            earth in the period of interest.\n",
    "   PRECTOTCORR: The bias corrected average of total precipitation at the surface of the earth \n",
    "                in water mass (includes water content in snow)\n",
    "   EVPTRNS: The evapotranspiration energy flux at the surface of the earth\n",
    "   ALLSKY_SFC_PAR_TOT: The total Photosynthetically Active Radiation (PAR) incident \n",
    "         on a horizontal plane at the surface of the earth under all sky conditions\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# for available parameter names, \n",
    "#       see https://gist.github.com/abelcallejo/d68e70f43ffa1c8c9f6b5e93010704b8\n",
    "# focused on growing season, which is April to October\n",
    "base_url = r\"https://power.larc.nasa.gov/api/temporal/daily/point?\"\n",
    "base_url += 'parameters=T2M_MAX,T2M_MIN,PRECTOTCORR,GWETROOT,EVPTRNS,ALLSKY_SFC_PAR_TOT&'\n",
    "base_url += 'community=RE&longitude={longitude}&latitude={latitude}&start={year}0401&end={year}1031&format=JSON'\n",
    "# print(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecc0e338",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['type', 'geometry', 'properties', 'header', 'messages', 'parameters', 'times'])\n",
      "          T2M_MAX  T2M_MIN  PRECTOTCORR  GWETROOT  EVPTRNS  ALLSKY_SFC_PAR_TOT\n",
      "20140401    14.27     5.53         1.01      0.80     0.18              117.24\n",
      "20140402    12.88     3.26         4.37      0.80     0.07               69.87\n",
      "20140403    17.19     3.97        52.73      0.85     0.00               18.46\n",
      "20140404    14.93     0.83         2.50      0.87     0.04               37.51\n",
      "20140405     9.79    -1.97         0.00      0.85     0.08              116.94\n",
      "\n",
      "14.27\n"
     ]
    }
   ],
   "source": [
    "def fetch_weather_county_year(county, year):\n",
    "    row = dfcty.loc[dfcty['County'] == county]\n",
    "    lon = row['Longitude'][0]\n",
    "    lat = row['Latitude'][0]\n",
    "    api_request_url = base_url.format(longitude=lon, latitude=lat, year=str(year))\n",
    "\n",
    "    response = requests.get(url=api_request_url, verify=True, timeout=30.00)\n",
    "    # print(response.status_code)\n",
    "    content = json.loads(response.content.decode('utf-8'))\n",
    "    print(type(content))\n",
    "    print(content.keys())\n",
    "    weather = content['properties']['parameter']\n",
    "\n",
    "    df = pd.DataFrame(weather)\n",
    "    \n",
    "    return df, weather\n",
    "\n",
    "df, weather = fetch_weather_county_year('Adams', 2014)\n",
    "\n",
    "# examining the output\n",
    "print(df.head())\n",
    "\n",
    "print()\n",
    "    \n",
    "print(weather['T2M_MAX']['20140401'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6e06e0",
   "metadata": {},
   "source": [
    "## <span style=color:blue>Grouping the data into months     </span>\n",
    "\n",
    "<span style=color:blue>Continuing to work with just Adams County.  Should package as a function... </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b84cae96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          T2M_MAX  T2M_MIN  PRECTOTCORR  GWETROOT  EVPTRNS  ALLSKY_SFC_PAR_TOT\n",
      "DATE                                                                          \n",
      "20140401    14.27     5.53         1.01      0.80     0.18              117.24\n",
      "20140402    12.88     3.26         4.37      0.80     0.07               69.87\n",
      "20140403    17.19     3.97        52.73      0.85     0.00               18.46\n",
      "20140404    14.93     0.83         2.50      0.87     0.04               37.51\n",
      "20140405     9.79    -1.97         0.00      0.85     0.08              116.94\n"
     ]
    }
   ],
   "source": [
    "# Want to have a name for the index of my dataframe\n",
    "df = df.rename_axis(index='DATE')\n",
    "print(df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7226f175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          T2M_MAX    T2M_MIN  PRECTOTCORR  GWETROOT  ALLSKY_SFC_PAR_TOT\n",
      "DATE                                                                   \n",
      "201404  16.305333   3.215000       125.82  0.833000             2840.03\n",
      "201405  21.613871  10.206129        92.08  0.795161             3515.73\n",
      "201406  26.442667  16.716000       143.19  0.741000             3441.92\n",
      "201407  25.886452  14.771935        48.41  0.640645             3526.86\n",
      "201408  28.519032  16.899677       107.01  0.576129             3229.78\n",
      "201409  23.733667  11.329667        83.94  0.606667             2631.40\n"
     ]
    }
   ],
   "source": [
    "# convert index to datetime format\n",
    "df.index = pd.to_datetime(df.index, format='%Y%m%d')\n",
    "df_monthly = df.resample('M').agg({'T2M_MAX':'mean',\n",
    "                                       'T2M_MIN':'mean',\n",
    "                                       'PRECTOTCORR':'sum',\n",
    "                                       'GWETROOT':'mean',\n",
    "                                       'ALLSKY_SFC_PAR_TOT':'sum'})\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "dfTMAX = df[['T2M_MAX']].copy()\n",
    "print(dfTMAX.head(5))\n",
    "\n",
    "\n",
    "# convert index to datetime format\n",
    "dfTMAX.index = pd.to_datetime(dfTMAX.index, format='%Y%m%d')\n",
    "print(dfTMAX.head(5))\n",
    "\n",
    "# resample to monthly frequency and calculate sum of T2M values\n",
    "df_monthly = dfTMAX.resample('M').mean()\n",
    "'''\n",
    "\n",
    "# convert index back to string format YYYYMM\n",
    "df_monthly.index = df_monthly.index.strftime('%Y%m')\n",
    "\n",
    "# rename column to T2M_SUM\n",
    "# df_monthly = df_monthly.rename(columns={'T2M': 'T2M_SUM'})\n",
    "\n",
    "print(df_monthly.head(6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ecf7ee",
   "metadata": {},
   "source": [
    "### <span style=color:blue>As a next step, I will create a df with single row and 36 columns, named \"2014-04__T2M_MAX\", \"2014-05__T2M_MAX\", etc.    </span>\n",
    "\n",
    "<span style=color:blue>Is there an elegant way to do that?  I am imaging a nested loop - which would get time-consuming for doing numerous states and counties</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5aad28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
