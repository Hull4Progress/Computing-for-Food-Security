{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b15a04c",
   "metadata": {},
   "source": [
    "## <span style=color:blue>Fetching GAEZ soil data for an ML pipeline</span>\n",
    "\n",
    "###  <span style=color:blue>Note: rather than using GAEZ, you might want to use the ISRIC soil data. </span>\n",
    "\n",
    "<span style=color:blue>E.g., see https://soilgrids.org and https://www.isric.org/explore/soilgrids/faq-soilgrids.  (It may take some digging around to make things work.  You probably want to use the EPSG:4326 (Plate Carre) projection.) Also, if you are working with yield data at the county level, then you might want to use soil grid data at the 5k x 5k gridsize, rather than then 1km x 1km or 250m x 250m gridsize. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9be255e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This useful if I want to give unique names to directories or files\n",
    "import datetime\n",
    "def curr_timestamp():\n",
    "    current_datetime = datetime.datetime.now()\n",
    "    formatted_datetime = current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    return formatted_datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c7b27b",
   "metadata": {},
   "source": [
    "### <span style=color:blue>Fetching the file state_county_lon_lat.csv which will be used below</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8742274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  state_name county_name        lon        lat\n",
      "0   ILLINOIS      BUREAU -89.534118  41.401629\n",
      "1   ILLINOIS     CARROLL -89.955679  42.064735\n",
      "2   ILLINOIS       HENRY -90.117744  41.341855\n",
      "3   ILLINOIS  JO DAVIESS -90.174374  42.350666\n",
      "4   ILLINOIS         LEE -89.286030  41.747311\n",
      "\n",
      "559\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "archive_dir = '/Users/rick/AG-CODE--v03/ML-ARCHIVES--v01/'\n",
    "scll_filename = 'state_county_lon_lat.csv'\n",
    "\n",
    "df_scll = pd.read_csv(archive_dir + scll_filename)\n",
    "print(df_scll.head())\n",
    "print()\n",
    "print(len(df_scll))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94448daa",
   "metadata": {},
   "source": [
    "### <span style=color:blue>Fetching several .tif files using urllib.</span>\n",
    "\n",
    "<span style=color:blue>I selected this by visual inspection of various GAEZ data sets.  I was looking for data based on soil that appeared to differentiate parts of my region of interest.</span>\n",
    "    \n",
    "### <span style=color:blue>Note: for the 1st, 3rd and 4th tif files fetched below, the pixel values are categorical.  So we will have to use one-hot encodings for these</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69e26a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['AEZ_classes', 'nutr_ret_high', 'soil_qual_high', 'soil_qual_low', 'suit_irrig_high_soy'])\n",
      "/Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__AEZ_classes.tif\n",
      "/Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__nutr_ret_high.tif\n",
      "/Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__soil_qual_high.tif\n",
      "/Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__soil_qual_low.tif\n",
      "/Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__suit_irrig_high_soy.tif\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "\n",
    "tif_dir = \"/Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/\"\n",
    "\n",
    "url = {}\n",
    "\n",
    "# using Land and Water Resources / Dominant AEZ class (33 classes) at 5 arc-minutes\n",
    "# Based on 33 AEZ classes, even though pixel values are integer\n",
    "url['AEZ_classes'] = \"https://s3.eu-west-1.amazonaws.com/data.gaezdev.aws.fao.org/LR/aez/aez_v9v2red_5m_CRUTS32_Hist_8110_100_avg.tif\"\n",
    "\n",
    "\n",
    "# Using the URL of TIF file Soil Resources / Nutrient retention capacity, high inputs\n",
    "# Based on 1 to 10, corresponding to bands 0.0 to 0.1; 0.1 to 02; etc.  So basically a numeric parameter\n",
    "url['nutr_ret_high'] = \"https://s3.eu-west-1.amazonaws.com/data.gaezdev.aws.fao.org/LR/soi1/SQ2_mze_v9aH.tif\"\n",
    "\n",
    "# using Land and Water Resources / Soil Resources / Most limiting soil quality rating factor, high inputs\n",
    "# Based on 11 soil categories (and water), even though pixel values are integer\n",
    "url['soil_qual_high'] = \"https://s3.eu-west-1.amazonaws.com/data.gaezdev.aws.fao.org/LR/soi1/SQ0_mze_v9aH.tif\"\n",
    "\n",
    "# using Land and Water Resources / Soil Resources / Most limiting soil quality rating factor, low inputs\n",
    "# same as previous\n",
    "url['soil_qual_low'] = \"https://s3.eu-west-1.amazonaws.com/data.gaezdev.aws.fao.org/LR/soi1/SQ0_mze_v9aL.tif\"\n",
    "\n",
    "# Leaving this one out because it is 43200 x 21600 pixels; don't want to work with different size input for now...\n",
    "# using Land and Water Resources / Soil suitability, rain-fed, low-inputs\n",
    "# url['soil_suit_rain_low'] = \"https://s3.eu-west-1.amazonaws.com/data.gaezdev.aws.fao.org/LR/soi2/siLr_sss_mze.tif\"\n",
    "\n",
    "# using Suitability and Attainable Yield / Suitability Index / Suitability index range (0-10000);\n",
    "#   within this chose crop = soybean; time period = 1981 to 2010; others empty\n",
    "# this has numeric values from 0 to 10,000\n",
    "url['suit_irrig_high_soy'] = \"https://s3.eu-west-1.amazonaws.com/data.gaezdev.aws.fao.org/res05/CRUTS32/Hist/8110H/suHi_soy.tif\"\n",
    "\n",
    "urlkeys = url.keys()\n",
    "print(urlkeys)\n",
    "\n",
    "# Fetch the TIF files using the associated URLs\n",
    "\n",
    "curr = curr_timestamp()\n",
    "fileFullName = {}\n",
    "\n",
    "# fetching the tif files from web and writing into local files\n",
    "for k in urlkeys:\n",
    "    fileFullName[k] = tif_dir + curr + '__' + k + '.tif'\n",
    "    print(fileFullName[k])\n",
    "    urllib.request.urlretrieve(url[k], fileFullName[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae795c3a",
   "metadata": {},
   "source": [
    "### <span style=color:blue>Fetching meta-data about the .tif files using GDAL, specifically the command-line operator gdalinfo.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e258b207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " AEZ_classes\n",
      "{\n",
      "  \"band_count\": 1,\n",
      "  \"size\": [\n",
      "    4320,\n",
      "    2160\n",
      "  ]\n",
      "}\n",
      "\n",
      " nutr_ret_high\n",
      "{\n",
      "  \"band_count\": 1,\n",
      "  \"size\": [\n",
      "    4320,\n",
      "    2160\n",
      "  ]\n",
      "}\n",
      "\n",
      " soil_qual_high\n",
      "{\n",
      "  \"band_count\": 1,\n",
      "  \"size\": [\n",
      "    4320,\n",
      "    2160\n",
      "  ]\n",
      "}\n",
      "\n",
      " soil_qual_low\n",
      "{\n",
      "  \"band_count\": 1,\n",
      "  \"size\": [\n",
      "    4320,\n",
      "    2160\n",
      "  ]\n",
      "}\n",
      "\n",
      " suit_irrig_high_soy\n",
      "{\n",
      "  \"band_count\": 1,\n",
      "  \"size\": [\n",
      "    4320,\n",
      "    2160\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import subprocess\n",
    "\n",
    "def pull_useful(ginfo):  # should give as input the result.stdout from calling gdalinfo -json\n",
    "    useful = {}\n",
    "    useful['band_count'] = len(ginfo['bands'])\n",
    "    # useful['cornerCoordinates'] = ginfo['cornerCoordinates']\n",
    "    # useful['proj:transform'] = ginfo['stac']['proj:transform']\n",
    "    useful['size'] = ginfo['size']\n",
    "    # useful['bbox'] = ginfo['stac']['proj:projjson']['bbox']\n",
    "    # useful['espgEncoding'] = ginfo['stac']['proj:epsg']\n",
    "    return useful\n",
    "\n",
    "gdalInfoReq = {}\n",
    "gdalInfo = {}\n",
    "\n",
    "useful = {}\n",
    "for k in urlkeys:\n",
    "    gdalInfoReq[k] = \" \".join([\"gdalinfo\", \"-json\", fileFullName[k]])\n",
    "    # print(gdalInfoReq[k])\n",
    "    result = subprocess.run([gdalInfoReq[k]], shell=True, capture_output=True, text=True)\n",
    "    gdalInfo[k] = json.loads(result.stdout)\n",
    "    # if k == 'AEZ_classes':\n",
    "    #     print(json.dumps(gdalInfo[k], indent=2, sort_keys=True))\n",
    "\n",
    "    useful[k] = pull_useful(gdalInfo[k])\n",
    "    print('\\n', k)\n",
    "    print(json.dumps(useful[k], indent=2, sort_keys=True))\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350ee9e5",
   "metadata": {},
   "source": [
    "<span style=color:blue>Digression: simple example of parsing XML     </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "539b61d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "# here is a typical xml output from gdallocationinfo on tif with one band\n",
    "xmlstring = '''<Report pixel=\"1086\" line=\"583\">\n",
    "              <BandReport band=\"1\">\n",
    "                 <Value>17</Value>\n",
    "              </BandReport>\n",
    "            </Report>\n",
    "           '''\n",
    "\n",
    "# following https://docs.python.org/3/library/xml.etree.elementtree.html\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "root = ET.fromstring(xmlstring)\n",
    "\n",
    "# long-winded way to navigate to the value 17\n",
    "for child in root:\n",
    "    if child.tag == 'BandReport':\n",
    "        for child1 in child:\n",
    "            if child1.tag == 'Value':\n",
    "                value = child1.text\n",
    "                print(value)            \n",
    "\n",
    "# if you know the structure of the tree, then you can navigate with indexes\n",
    "print(root[0][0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e59da4",
   "metadata": {},
   "source": [
    "### <span style=color:blue>Fetching value of a pixel using gdallocationinfo.</span>\n",
    "\n",
    "<span style=color:blue>Note: All the .tif's we're using here have just one band</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08acca5e",
   "metadata": {},
   "source": [
    "<span style=color:blue>This next cell is a \"warm up\", working with just one tif file and one state-county pair.  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c6cc5840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  state_name county_name        lon        lat\n",
      "0   ILLINOIS      BUREAU -89.534118  41.401629\n",
      "-89.5341179 41.4016294 <class 'numpy.float64'> <class 'numpy.float64'>\n",
      "1086 583\n",
      "gdallocationinfo -xml /Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__AEZ_classes.tif 1086 583\n",
      "<Report pixel=\"1086\" line=\"583\">\n",
      "  <BandReport band=\"1\">\n",
      "    <Value>17</Value>\n",
      "  </BandReport>\n",
      "</Report>\n",
      "\n",
      "\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# converting from lat/long into a pixel location for a global tif with size 4320x2160\n",
    "def convert_to_pix(lon, lat):\n",
    "    x = round((lon + 180) * 12)\n",
    "    y = round((90 - lat) * 12)\n",
    "    return x,y\n",
    "\n",
    "# recall: fullFileName[k] holds full dir + file name for key k\n",
    "f = fileFullName['AEZ_classes']\n",
    "\n",
    "print(df_scll.iloc[[0]])\n",
    "test_lon = df_scll.iloc[0]['lon']\n",
    "test_lat = df_scll.iloc[0]['lat']\n",
    "print(test_lon, test_lat, type(test_lon), type(test_lat))\n",
    "\n",
    "\n",
    "x,y = convert_to_pix(test_lon, test_lat)\n",
    "\n",
    "print(x,y)\n",
    "\n",
    "# gdal terminal command to fectch pixel value\n",
    "val = \" \".join(['gdallocationinfo -xml', fileFullName['AEZ_classes'], str(x), str(y)])\n",
    "print(val)\n",
    "\n",
    "result = subprocess.run([val], \n",
    "                         shell=True, capture_output=True,text=True)\n",
    "print(result.stdout)\n",
    "print(result.stderr)\n",
    "\n",
    "root = ET.fromstring(result.stdout)\n",
    "val_out = root[0][0].text\n",
    "print(val_out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647be7b6",
   "metadata": {},
   "source": [
    "<span style=color:blue>Now checking the structure of the outputs from each of the 5 .tif files</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ecff1b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AEZ_classes\n",
      "gdallocationinfo -xml /Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__AEZ_classes.tif 1086 583\n",
      "<Report pixel=\"1086\" line=\"583\">\n",
      "  <BandReport band=\"1\">\n",
      "    <Value>17</Value>\n",
      "  </BandReport>\n",
      "</Report>\n",
      "\n",
      "\n",
      "17\n",
      "\n",
      "nutr_ret_high\n",
      "gdallocationinfo -xml /Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__nutr_ret_high.tif 1086 583\n",
      "<Report pixel=\"1086\" line=\"583\">\n",
      "  <BandReport band=\"1\">\n",
      "    <Value>10</Value>\n",
      "  </BandReport>\n",
      "</Report>\n",
      "\n",
      "\n",
      "10\n",
      "\n",
      "soil_qual_high\n",
      "gdallocationinfo -xml /Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__soil_qual_high.tif 1086 583\n",
      "<Report pixel=\"1086\" line=\"583\">\n",
      "  <BandReport band=\"1\">\n",
      "    <Value>10</Value>\n",
      "  </BandReport>\n",
      "</Report>\n",
      "\n",
      "\n",
      "10\n",
      "\n",
      "soil_qual_low\n",
      "gdallocationinfo -xml /Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__soil_qual_low.tif 1086 583\n",
      "<Report pixel=\"1086\" line=\"583\">\n",
      "  <BandReport band=\"1\">\n",
      "    <Value>8</Value>\n",
      "  </BandReport>\n",
      "</Report>\n",
      "\n",
      "\n",
      "8\n",
      "\n",
      "suit_irrig_high_soy\n",
      "gdallocationinfo -xml /Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__suit_irrig_high_soy.tif 1086 583\n",
      "<Report pixel=\"1086\" line=\"583\">\n",
      "  <BandReport band=\"1\">\n",
      "    <Value>10000</Value>\n",
      "  </BandReport>\n",
      "</Report>\n",
      "\n",
      "\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# still working with the location of first county -- in df_scll.iloc[[0]]\n",
    "\n",
    "for k in urlkeys:\n",
    "    print()\n",
    "    print(k)\n",
    "    \n",
    "    val = \" \".join(['gdallocationinfo -xml', fileFullName[k], str(x), str(y)])\n",
    "    print(val)\n",
    "\n",
    "    result = subprocess.run([val], \n",
    "                             shell=True, capture_output=True,text=True)\n",
    "    print(result.stdout)\n",
    "    print(result.stderr)\n",
    "\n",
    "    root = ET.fromstring(result.stdout)\n",
    "    val_out = root[0][0].text\n",
    "    print(val_out)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bc8727",
   "metadata": {},
   "source": [
    "<span style=color:blue>Defining function that takes as input a lon,lat and a key for tif file, and gives back the value for that lon, lat </span>\n",
    "\n",
    "<span style=color:blue>Note: the values in the XML are all strings, we will convert to int when loading into the new df that we are building</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9abf0437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdallocationinfo -xml /Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__AEZ_classes.tif 1086 583\n",
      "<Report pixel=\"1086\" line=\"583\">\n",
      "  <BandReport band=\"1\">\n",
      "    <Value>17</Value>\n",
      "  </BandReport>\n",
      "</Report>\n",
      "\n",
      "\n",
      "17\n",
      "\n",
      "gdallocationinfo -xml /Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__nutr_ret_high.tif 1086 583\n",
      "<Report pixel=\"1086\" line=\"583\">\n",
      "  <BandReport band=\"1\">\n",
      "    <Value>10</Value>\n",
      "  </BandReport>\n",
      "</Report>\n",
      "\n",
      "\n",
      "10\n",
      "\n",
      "gdallocationinfo -xml /Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__soil_qual_high.tif 1086 583\n",
      "<Report pixel=\"1086\" line=\"583\">\n",
      "  <BandReport band=\"1\">\n",
      "    <Value>10</Value>\n",
      "  </BandReport>\n",
      "</Report>\n",
      "\n",
      "\n",
      "10\n",
      "\n",
      "gdallocationinfo -xml /Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__soil_qual_low.tif 1086 583\n",
      "<Report pixel=\"1086\" line=\"583\">\n",
      "  <BandReport band=\"1\">\n",
      "    <Value>8</Value>\n",
      "  </BandReport>\n",
      "</Report>\n",
      "\n",
      "\n",
      "8\n",
      "\n",
      "gdallocationinfo -xml /Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__suit_irrig_high_soy.tif 1086 583\n",
      "<Report pixel=\"1086\" line=\"583\">\n",
      "  <BandReport band=\"1\">\n",
      "    <Value>10000</Value>\n",
      "  </BandReport>\n",
      "</Report>\n",
      "\n",
      "\n",
      "10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fetchs the value at lon-lat of the tif file associated with the specified key\n",
    "# returns a float\n",
    "def fetch_tif_value(lon, lat, key, verbose):\n",
    "    x,y = convert_to_pix(lon, lat)\n",
    "\n",
    "    val = \" \".join(['gdallocationinfo -xml', fileFullName[k], str(x), str(y)])\n",
    "    if verbose:\n",
    "        print(val)\n",
    "\n",
    "    result = subprocess.run([val], \n",
    "                             shell=True, capture_output=True,text=True)\n",
    "    if verbose:\n",
    "        print(result.stdout)\n",
    "        print(result.stderr)\n",
    "\n",
    "    root = ET.fromstring(result.stdout)\n",
    "    return int(root[0][0].text)\n",
    "\n",
    "for k in urlkeys:\n",
    "    val_out = fetch_tif_value(test_lon, test_lat,k, True)\n",
    "    print(val_out)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7315a36",
   "metadata": {},
   "source": [
    "<span style=color:blue>Now adding all 5 soil values to the rows of df_scll.  This takes a while to run. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1a68f6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  state_name county_name        lon        lat\n",
      "0   ILLINOIS      BUREAU -89.534118  41.401629\n",
      "1   ILLINOIS     CARROLL -89.955679  42.064735\n",
      "2   ILLINOIS       HENRY -90.117744  41.341855\n",
      "3   ILLINOIS  JO DAVIESS -90.174374  42.350666\n",
      "4   ILLINOIS         LEE -89.286030  41.747311\n",
      "559\n",
      "\n",
      "  state_name county_name        lon        lat  AEZ_classes  nutr_ret_high  \\\n",
      "0   ILLINOIS      BUREAU -89.534118  41.401629           17             10   \n",
      "1   ILLINOIS     CARROLL -89.955679  42.064735           17             10   \n",
      "2   ILLINOIS       HENRY -90.117744  41.341855           17             10   \n",
      "3   ILLINOIS  JO DAVIESS -90.174374  42.350666           17             10   \n",
      "4   ILLINOIS         LEE -89.286030  41.747311           17             10   \n",
      "\n",
      "   soil_qual_high  soil_qual_low  suit_irrig_high_soy  \n",
      "0              10              8                10000  \n",
      "1              10              9                10000  \n",
      "2              10              8                10000  \n",
      "3               8              8                 9709  \n",
      "4              10              8                10000  \n",
      "559\n",
      "\n",
      "AEZ_classes\n",
      "\n",
      "     AEZ_classes\n",
      "0             17\n",
      "9             20\n",
      "13            32\n",
      "37            27\n",
      "46            28\n",
      "80            18\n",
      "393           16\n",
      "396           19\n",
      "484           21\n",
      "\n",
      "nutr_ret_high\n",
      "\n",
      "     nutr_ret_high\n",
      "0               10\n",
      "164              8\n",
      "168              9\n",
      "\n",
      "soil_qual_high\n",
      "\n",
      "     soil_qual_high\n",
      "0                10\n",
      "3                 8\n",
      "50                9\n",
      "80                7\n",
      "81                6\n",
      "164               5\n",
      "168               4\n",
      "\n",
      "soil_qual_low\n",
      "\n",
      "     soil_qual_low\n",
      "0                8\n",
      "1                9\n",
      "10               7\n",
      "46               6\n",
      "60              10\n",
      "164              5\n",
      "168              4\n",
      "\n",
      "suit_irrig_high_soy\n",
      "\n",
      "     suit_irrig_high_soy\n",
      "0                  10000\n",
      "3                   9709\n",
      "13                    -1\n",
      "108                 9236\n",
      "109                 8921\n",
      "164                 7778\n",
      "167                 9695\n",
      "168                 7889\n",
      "174                 8385\n",
      "179                 8145\n",
      "185                 8650\n",
      "339                    0\n",
      "367                 7802\n",
      "373                 7803\n",
      "376                 8795\n",
      "385                 8222\n",
      "387                 9333\n",
      "392                 9552\n",
      "394                 7829\n",
      "397                 8240\n",
      "428                 8688\n",
      "437                 8066\n",
      "444                 8339\n",
      "445                 8193\n",
      "449                 8331\n",
      "451                 7965\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df3 = df_scll.copy()\n",
    "print(df3.head())\n",
    "print(len(df3))\n",
    "\n",
    "for k in urlkeys:\n",
    "    df3[k] = df3.apply(lambda r: fetch_tif_value(r['lon'], r['lat'], k, False), axis=1)\n",
    "    \n",
    "print()\n",
    "print(df3.head())\n",
    "print(len(df3))\n",
    "\n",
    "for k in urlkeys:\n",
    "    print()\n",
    "    print(k)\n",
    "    print()\n",
    "    print(df3[[k]].drop_duplicates().head(100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05679e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "172b7eb6",
   "metadata": {},
   "source": [
    "<span style=color:blue>Replacing the columns for 'AEZ_classes', 'soil_qual_high', 'soil_qual_low' with multiple \"1-hot\" columns.   (We could also use the OneHotEncoder from scikit, but I'm choosing to do it here and now on the raw data.)</span>\n",
    "\n",
    "<span style=color:blue>Following https://stackoverflow.com/questions/37292872/how-can-i-one-hot-encode-in-python</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "00f4d2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559\n",
      "  state_name county_name        lon        lat  nutr_ret_high  soil_qual_high  \\\n",
      "0   ILLINOIS      BUREAU -89.534118  41.401629             10              10   \n",
      "1   ILLINOIS     CARROLL -89.955679  42.064735             10              10   \n",
      "2   ILLINOIS       HENRY -90.117744  41.341855             10              10   \n",
      "3   ILLINOIS  JO DAVIESS -90.174374  42.350666             10               8   \n",
      "4   ILLINOIS         LEE -89.286030  41.747311             10              10   \n",
      "\n",
      "   soil_qual_low  suit_irrig_high_soy  16  17  18  19  20  21  27  28  32  \n",
      "0              8                10000   0   1   0   0   0   0   0   0   0  \n",
      "1              9                10000   0   1   0   0   0   0   0   0   0  \n",
      "2              8                10000   0   1   0   0   0   0   0   0   0  \n",
      "3              8                 9709   0   1   0   0   0   0   0   0   0  \n",
      "4              8                10000   0   1   0   0   0   0   0   0   0  \n",
      "['state_name', 'county_name', 'lon', 'lat', 'nutr_ret_high', 'soil_qual_high', 'soil_qual_low', 'suit_irrig_high_soy', 16, 17, 18, 19, 20, 21, 27, 28, 32]\n",
      "\n",
      "['state_name', 'county_name', 'lon', 'lat', 'nutr_ret_high', 'soil_qual_high', 'soil_qual_low', 'suit_irrig_high_soy', 'AEZ_1', 'AEZ_2', 'AEZ_3', 'AEZ_4', 'AEZ_5', 'AEZ_6', 'AEZ_7', 'AEZ_8', 'AEZ_9']\n",
      "  state_name county_name        lon        lat  nutr_ret_high  soil_qual_high  \\\n",
      "0   ILLINOIS      BUREAU -89.534118  41.401629             10              10   \n",
      "1   ILLINOIS     CARROLL -89.955679  42.064735             10              10   \n",
      "2   ILLINOIS       HENRY -90.117744  41.341855             10              10   \n",
      "3   ILLINOIS  JO DAVIESS -90.174374  42.350666             10               8   \n",
      "4   ILLINOIS         LEE -89.286030  41.747311             10              10   \n",
      "\n",
      "   soil_qual_low  suit_irrig_high_soy  AEZ_1  AEZ_2  AEZ_3  AEZ_4  AEZ_5  \\\n",
      "0              8                10000      0      1      0      0      0   \n",
      "1              9                10000      0      1      0      0      0   \n",
      "2              8                10000      0      1      0      0      0   \n",
      "3              8                 9709      0      1      0      0      0   \n",
      "4              8                10000      0      1      0      0      0   \n",
      "\n",
      "   AEZ_6  AEZ_7  AEZ_8  AEZ_9  \n",
      "0      0      0      0      0  \n",
      "1      0      0      0      0  \n",
      "2      0      0      0      0  \n",
      "3      0      0      0      0  \n",
      "4      0      0      0      0  \n"
     ]
    }
   ],
   "source": [
    "df4 = df3.copy()\n",
    "\n",
    "# Get one hot encoding of columns 'AEZ-classes'\n",
    "one_hot = pd.get_dummies(df4['AEZ_classes'])\n",
    "# Drop original as it is now encoded\n",
    "df4 = df4.drop('AEZ_classes',axis = 1)\n",
    "# Join the encoded df\n",
    "df4 = df4.join(one_hot)\n",
    "\n",
    "print(len(df4))\n",
    "print(df4.head())\n",
    "print(df4.columns.tolist())\n",
    "# output was ['state_name', 'county_name', 'lon', 'lat', 'nutr_ret_high', \n",
    "#             'soil_qual_high', 'soil_qual_low', 'suit_irrig_high_soy', \n",
    "#              16, 17, 18, 19, 20, 21, 27, 28, 32]\n",
    "\n",
    "print()\n",
    "cols = { 16: 'AEZ_1',\n",
    "         17: 'AEZ_2',\n",
    "         18: 'AEZ_3',\n",
    "         19: 'AEZ_4',\n",
    "         20: 'AEZ_5',\n",
    "         21: 'AEZ_6',\n",
    "         27: 'AEZ_7',\n",
    "         28: 'AEZ_8',\n",
    "         32: 'AEZ_9'}\n",
    "df4 = df4.rename(columns=cols)\n",
    "print(df4.columns.tolist())\n",
    "print(df4.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "10d1d85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559\n",
      "  state_name county_name        lon        lat  nutr_ret_high  soil_qual_low  \\\n",
      "0   ILLINOIS      BUREAU -89.534118  41.401629             10              8   \n",
      "1   ILLINOIS     CARROLL -89.955679  42.064735             10              9   \n",
      "2   ILLINOIS       HENRY -90.117744  41.341855             10              8   \n",
      "3   ILLINOIS  JO DAVIESS -90.174374  42.350666             10              8   \n",
      "4   ILLINOIS         LEE -89.286030  41.747311             10              8   \n",
      "\n",
      "   suit_irrig_high_soy  AEZ_1  AEZ_2  AEZ_3  ...  AEZ_7  AEZ_8  AEZ_9  4  5  \\\n",
      "0                10000      0      1      0  ...      0      0      0  0  0   \n",
      "1                10000      0      1      0  ...      0      0      0  0  0   \n",
      "2                10000      0      1      0  ...      0      0      0  0  0   \n",
      "3                 9709      0      1      0  ...      0      0      0  0  0   \n",
      "4                10000      0      1      0  ...      0      0      0  0  0   \n",
      "\n",
      "   6  7  8  9  10  \n",
      "0  0  0  0  0   1  \n",
      "1  0  0  0  0   1  \n",
      "2  0  0  0  0   1  \n",
      "3  0  0  1  0   0  \n",
      "4  0  0  0  0   1  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "['state_name', 'county_name', 'lon', 'lat', 'nutr_ret_high', 'soil_qual_low', 'suit_irrig_high_soy', 'AEZ_1', 'AEZ_2', 'AEZ_3', 'AEZ_4', 'AEZ_5', 'AEZ_6', 'AEZ_7', 'AEZ_8', 'AEZ_9', 4, 5, 6, 7, 8, 9, 10]\n",
      "\n",
      "['state_name', 'county_name', 'lon', 'lat', 'nutr_ret_high', 'soil_qual_low', 'suit_irrig_high_soy', 'AEZ_1', 'AEZ_2', 'AEZ_3', 'AEZ_4', 'AEZ_5', 'AEZ_6', 'AEZ_7', 'AEZ_8', 'AEZ_9', 'SQH_1', 'SQH_2', 'SQH_3', 'SQH_4', 'SQH_5', 'SQH_6', 'SQH_7']\n",
      "  state_name county_name        lon        lat  nutr_ret_high  soil_qual_low  \\\n",
      "0   ILLINOIS      BUREAU -89.534118  41.401629             10              8   \n",
      "1   ILLINOIS     CARROLL -89.955679  42.064735             10              9   \n",
      "2   ILLINOIS       HENRY -90.117744  41.341855             10              8   \n",
      "3   ILLINOIS  JO DAVIESS -90.174374  42.350666             10              8   \n",
      "4   ILLINOIS         LEE -89.286030  41.747311             10              8   \n",
      "\n",
      "   suit_irrig_high_soy  AEZ_1  AEZ_2  AEZ_3  ...  AEZ_7  AEZ_8  AEZ_9  SQH_1  \\\n",
      "0                10000      0      1      0  ...      0      0      0      0   \n",
      "1                10000      0      1      0  ...      0      0      0      0   \n",
      "2                10000      0      1      0  ...      0      0      0      0   \n",
      "3                 9709      0      1      0  ...      0      0      0      0   \n",
      "4                10000      0      1      0  ...      0      0      0      0   \n",
      "\n",
      "   SQH_2  SQH_3  SQH_4  SQH_5  SQH_6  SQH_7  \n",
      "0      0      0      0      0      0      1  \n",
      "1      0      0      0      0      0      1  \n",
      "2      0      0      0      0      0      1  \n",
      "3      0      0      0      1      0      0  \n",
      "4      0      0      0      0      0      1  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# making a copy of df4, because may run this cell a couple of times as I develop it\n",
    "df5 = df4.copy()\n",
    "\n",
    "# Get one hot encoding of columns 'soil_qual_high'\n",
    "one_hot1 = pd.get_dummies(df5['soil_qual_high'])\n",
    "# Drop original as it is now encoded\n",
    "df5 = df5.drop('soil_qual_high',axis = 1)\n",
    "# Join the encoded df\n",
    "df5 = df5.join(one_hot1)\n",
    "\n",
    "print(len(df5))\n",
    "print(df5.head())\n",
    "print(df5.columns.tolist())\n",
    "# output was ['state_name', 'county_name', 'lon', 'lat', 'nutr_ret_high', \n",
    "#             'soil_qual_low', 'suit_irrig_high_soy', 'AEZ_1', 'AEZ_2', 'AEZ_3', \n",
    "#             'AEZ_4', 'AEZ_5', 'AEZ_6', 'AEZ_7', 'AEZ_8', 'AEZ_9', \n",
    "#             4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "print()\n",
    "cols = { 4: 'SQH_1',\n",
    "         5: 'SQH_2',\n",
    "         6: 'SQH_3',\n",
    "         7: 'SQH_4',\n",
    "         8: 'SQH_5',\n",
    "         9: 'SQH_6',\n",
    "         10: 'SQH_7'}\n",
    "df5 = df5.rename(columns=cols)\n",
    "print(df5.columns.tolist())\n",
    "print(df5.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f02da3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559\n",
      "  state_name county_name        lon        lat  nutr_ret_high  \\\n",
      "0   ILLINOIS      BUREAU -89.534118  41.401629             10   \n",
      "1   ILLINOIS     CARROLL -89.955679  42.064735             10   \n",
      "2   ILLINOIS       HENRY -90.117744  41.341855             10   \n",
      "3   ILLINOIS  JO DAVIESS -90.174374  42.350666             10   \n",
      "4   ILLINOIS         LEE -89.286030  41.747311             10   \n",
      "\n",
      "   suit_irrig_high_soy  AEZ_1  AEZ_2  AEZ_3  AEZ_4  ...  SQH_5  SQH_6  SQH_7  \\\n",
      "0                10000      0      1      0      0  ...      0      0      1   \n",
      "1                10000      0      1      0      0  ...      0      0      1   \n",
      "2                10000      0      1      0      0  ...      0      0      1   \n",
      "3                 9709      0      1      0      0  ...      1      0      0   \n",
      "4                10000      0      1      0      0  ...      0      0      1   \n",
      "\n",
      "   4  5  6  7  8  9  10  \n",
      "0  0  0  0  0  1  0   0  \n",
      "1  0  0  0  0  0  1   0  \n",
      "2  0  0  0  0  1  0   0  \n",
      "3  0  0  0  0  1  0   0  \n",
      "4  0  0  0  0  1  0   0  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "['state_name', 'county_name', 'lon', 'lat', 'nutr_ret_high', 'suit_irrig_high_soy', 'AEZ_1', 'AEZ_2', 'AEZ_3', 'AEZ_4', 'AEZ_5', 'AEZ_6', 'AEZ_7', 'AEZ_8', 'AEZ_9', 'SQH_1', 'SQH_2', 'SQH_3', 'SQH_4', 'SQH_5', 'SQH_6', 'SQH_7', 4, 5, 6, 7, 8, 9, 10]\n",
      "\n",
      "['state_name', 'county_name', 'lon', 'lat', 'nutr_ret_high', 'suit_irrig_high_soy', 'AEZ_1', 'AEZ_2', 'AEZ_3', 'AEZ_4', 'AEZ_5', 'AEZ_6', 'AEZ_7', 'AEZ_8', 'AEZ_9', 'SQH_1', 'SQH_2', 'SQH_3', 'SQH_4', 'SQH_5', 'SQH_6', 'SQH_7', 'SQL_1', 'SQL_2', 'SQL_3', 'SQL_4', 'SQL_5', 'SQL_6', 'SQL_7']\n",
      "  state_name county_name        lon        lat  nutr_ret_high  \\\n",
      "0   ILLINOIS      BUREAU -89.534118  41.401629             10   \n",
      "1   ILLINOIS     CARROLL -89.955679  42.064735             10   \n",
      "2   ILLINOIS       HENRY -90.117744  41.341855             10   \n",
      "3   ILLINOIS  JO DAVIESS -90.174374  42.350666             10   \n",
      "4   ILLINOIS         LEE -89.286030  41.747311             10   \n",
      "\n",
      "   suit_irrig_high_soy  AEZ_1  AEZ_2  AEZ_3  AEZ_4  ...  SQH_5  SQH_6  SQH_7  \\\n",
      "0                10000      0      1      0      0  ...      0      0      1   \n",
      "1                10000      0      1      0      0  ...      0      0      1   \n",
      "2                10000      0      1      0      0  ...      0      0      1   \n",
      "3                 9709      0      1      0      0  ...      1      0      0   \n",
      "4                10000      0      1      0      0  ...      0      0      1   \n",
      "\n",
      "   SQL_1  SQL_2  SQL_3  SQL_4  SQL_5  SQL_6  SQL_7  \n",
      "0      0      0      0      0      1      0      0  \n",
      "1      0      0      0      0      0      1      0  \n",
      "2      0      0      0      0      1      0      0  \n",
      "3      0      0      0      0      1      0      0  \n",
      "4      0      0      0      0      1      0      0  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# making a copy of df5, because may run this cell a couple of times as I develop it\n",
    "df6 = df5.copy()\n",
    "\n",
    "# Get one hot encoding of columns 'soil_qual_low'\n",
    "one_hot2 = pd.get_dummies(df6['soil_qual_low'])\n",
    "# Drop original as it is now encoded\n",
    "df6 = df6.drop('soil_qual_low',axis = 1)\n",
    "# Join the encoded df\n",
    "df6 = df6.join(one_hot2)\n",
    "\n",
    "print(len(df6))\n",
    "print(df6.head())\n",
    "print(df6.columns.tolist())\n",
    "# output was ['state_name', 'county_name', 'lon', 'lat', 'nutr_ret_high', \n",
    "#             'suit_irrig_high_soy', 'AEZ_1', 'AEZ_2', 'AEZ_3', 'AEZ_4', \n",
    "#             'AEZ_5', 'AEZ_6', 'AEZ_7', 'AEZ_8', 'AEZ_9', \n",
    "#             'SQH_1', 'SQH_2', 'SQH_3', 'SQH_4', 'SQH_5', 'SQH_6', 'SQH_7', \n",
    "#              4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "print()\n",
    "cols = { 4: 'SQL_1',\n",
    "         5: 'SQL_2',\n",
    "         6: 'SQL_3',\n",
    "         7: 'SQL_4',\n",
    "         8: 'SQL_5',\n",
    "         9: 'SQL_6',\n",
    "         10: 'SQL_7'}\n",
    "df6 = df6.rename(columns=cols)\n",
    "print(df6.columns.tolist())\n",
    "print(df6.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae805ca",
   "metadata": {},
   "source": [
    "<span style=color:blue>Archiving this df     </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0fdb5fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote file:  /Users/rick/AG-CODE--v03/ML-ARCHIVES--v01/state_county_lon_lat_soil.csv\n"
     ]
    }
   ],
   "source": [
    "archives_dir = '/Users/rick/AG-CODE--v03/ML-ARCHIVES--v01/'\n",
    "filename = 'state_county_lon_lat_soil.csv'\n",
    "df6.to_csv(archives_dir + filename, index=False)\n",
    "print('wrote file: ', archives_dir + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c5a654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pygdal2]",
   "language": "python",
   "name": "conda-env-pygdal2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
