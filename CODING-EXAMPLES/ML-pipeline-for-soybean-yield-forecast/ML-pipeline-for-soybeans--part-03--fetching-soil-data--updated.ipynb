{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b15a04c",
   "metadata": {},
   "source": [
    "## <span style=color:blue>Fetching GAEZ soil data for an ML pipeline</span>\n",
    "\n",
    "###  <span style=color:blue>Note: rather than using GAEZ, you might want to use the ISRIC soil data. </span>\n",
    "\n",
    "<span style=color:blue>E.g., see https://soilgrids.org and https://www.isric.org/explore/soilgrids/faq-soilgrids.  (It may take some digging around to make things work.  You probably want to use the EPSG:4326 (Plate Carre) projection.) Also, if you are working with yield data at the county level, then you might want to use soil grid data at the 5k x 5k gridsize, rather than then 1km x 1km or 250m x 250m gridsize. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9be255e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This useful if I want to give unique names to directories or files\n",
    "import datetime\n",
    "def curr_timestamp():\n",
    "    current_datetime = datetime.datetime.now()\n",
    "    formatted_datetime = current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    return formatted_datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c7b27b",
   "metadata": {},
   "source": [
    "### <span style=color:blue>Fetching the file state_county_lon_lat.csv which will be used below</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8742274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  state_name county_name        lon        lat\n",
      "0   ILLINOIS      BUREAU -89.534118  41.401629\n",
      "1   ILLINOIS     CARROLL -89.955679  42.064735\n",
      "2   ILLINOIS       HENRY -90.117744  41.341855\n",
      "3   ILLINOIS  JO DAVIESS -90.174374  42.350666\n",
      "4   ILLINOIS         LEE -89.286030  41.747311\n",
      "\n",
      "559\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "archive_dir = '/Users/rick/AG-CODE--v03/ML-ARCHIVES--v01/'\n",
    "scll_filename = 'state_county_lon_lat.csv'\n",
    "\n",
    "df_scll = pd.read_csv(archive_dir + scll_filename)\n",
    "print(df_scll.head())\n",
    "print()\n",
    "print(len(df_scll))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94448daa",
   "metadata": {},
   "source": [
    "### <span style=color:blue>Fetching several .tif files using urllib.</span>\n",
    "\n",
    "<span style=color:blue>I selected this by visual inspection of various GAEZ data sets.  I was looking for data based on soil that appeared to differentiate parts of my region of interest.</span>\n",
    "    \n",
    "### <span style=color:blue>Note: for the 1st, 3rd and 4th tif files fetched below, the pixel values are categorical.  So we will have to use one-hot encodings for these</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69e26a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['AEZ_classes', 'nutr_ret_high', 'soil_qual_high', 'soil_qual_low', 'suit_irrig_high_soy'])\n",
      "/Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__AEZ_classes.tif\n",
      "/Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__nutr_ret_high.tif\n",
      "/Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__soil_qual_high.tif\n",
      "/Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__soil_qual_low.tif\n",
      "/Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__suit_irrig_high_soy.tif\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "\n",
    "tif_dir = \"/Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/\"\n",
    "\n",
    "url = {}\n",
    "\n",
    "# using Land and Water Resources / Dominant AEZ class (33 classes) at 5 arc-minutes\n",
    "# Based on 33 AEZ classes, even though pixel values are integer\n",
    "url['AEZ_classes'] = \"https://s3.eu-west-1.amazonaws.com/data.gaezdev.aws.fao.org/LR/aez/aez_v9v2red_5m_CRUTS32_Hist_8110_100_avg.tif\"\n",
    "\n",
    "\n",
    "# Using the URL of TIF file Soil Resources / Nutrient retention capacity, high inputs\n",
    "# Based on 1 to 10, corresponding to bands 0.0 to 0.1; 0.1 to 02; etc.  So basically a numeric parameter\n",
    "url['nutr_ret_high'] = \"https://s3.eu-west-1.amazonaws.com/data.gaezdev.aws.fao.org/LR/soi1/SQ2_mze_v9aH.tif\"\n",
    "\n",
    "# using Land and Water Resources / Soil Resources / Most limiting soil quality rating factor, high inputs\n",
    "# Based on 11 soil categories (and water), even though pixel values are integer\n",
    "url['soil_qual_high'] = \"https://s3.eu-west-1.amazonaws.com/data.gaezdev.aws.fao.org/LR/soi1/SQ0_mze_v9aH.tif\"\n",
    "\n",
    "# using Land and Water Resources / Soil Resources / Most limiting soil quality rating factor, low inputs\n",
    "# same as previous\n",
    "url['soil_qual_low'] = \"https://s3.eu-west-1.amazonaws.com/data.gaezdev.aws.fao.org/LR/soi1/SQ0_mze_v9aL.tif\"\n",
    "\n",
    "# Leaving this one out because it is 43200 x 21600 pixels; don't want to work with different size input for now...\n",
    "# using Land and Water Resources / Soil suitability, rain-fed, low-inputs\n",
    "# url['soil_suit_rain_low'] = \"https://s3.eu-west-1.amazonaws.com/data.gaezdev.aws.fao.org/LR/soi2/siLr_sss_mze.tif\"\n",
    "\n",
    "# using Suitability and Attainable Yield / Suitability Index / Suitability index range (0-10000);\n",
    "#   within this chose crop = soybean; time period = 1981 to 2010; others empty\n",
    "# this has numeric values from 0 to 10,000\n",
    "url['suit_irrig_high_soy'] = \"https://s3.eu-west-1.amazonaws.com/data.gaezdev.aws.fao.org/res05/CRUTS32/Hist/8110H/suHi_soy.tif\"\n",
    "\n",
    "urlkeys = url.keys()\n",
    "print(urlkeys)\n",
    "\n",
    "# Fetch the TIF files using the associated URLs\n",
    "\n",
    "curr = curr_timestamp()\n",
    "fileFullName = {}\n",
    "\n",
    "# fetching the tif files from web and writing into local files\n",
    "for k in urlkeys:\n",
    "    fileFullName[k] = tif_dir + curr + '__' + k + '.tif'\n",
    "    print(fileFullName[k])\n",
    "    urllib.request.urlretrieve(url[k], fileFullName[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae795c3a",
   "metadata": {},
   "source": [
    "### <span style=color:blue>Fetching meta-data about the .tif files using GDAL, specifically the command-line operator gdalinfo.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e258b207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " AEZ_classes\n",
      "{\n",
      "  \"band_count\": 1,\n",
      "  \"size\": [\n",
      "    4320,\n",
      "    2160\n",
      "  ]\n",
      "}\n",
      "\n",
      " nutr_ret_high\n",
      "{\n",
      "  \"band_count\": 1,\n",
      "  \"size\": [\n",
      "    4320,\n",
      "    2160\n",
      "  ]\n",
      "}\n",
      "\n",
      " soil_qual_high\n",
      "{\n",
      "  \"band_count\": 1,\n",
      "  \"size\": [\n",
      "    4320,\n",
      "    2160\n",
      "  ]\n",
      "}\n",
      "\n",
      " soil_qual_low\n",
      "{\n",
      "  \"band_count\": 1,\n",
      "  \"size\": [\n",
      "    4320,\n",
      "    2160\n",
      "  ]\n",
      "}\n",
      "\n",
      " suit_irrig_high_soy\n",
      "{\n",
      "  \"band_count\": 1,\n",
      "  \"size\": [\n",
      "    4320,\n",
      "    2160\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import subprocess\n",
    "\n",
    "def pull_useful(ginfo):  # should give as input the result.stdout from calling gdalinfo -json\n",
    "    useful = {}\n",
    "    useful['band_count'] = len(ginfo['bands'])\n",
    "    # useful['cornerCoordinates'] = ginfo['cornerCoordinates']\n",
    "    # useful['proj:transform'] = ginfo['stac']['proj:transform']\n",
    "    useful['size'] = ginfo['size']\n",
    "    # useful['bbox'] = ginfo['stac']['proj:projjson']['bbox']\n",
    "    # useful['espgEncoding'] = ginfo['stac']['proj:epsg']\n",
    "    return useful\n",
    "\n",
    "gdalInfoReq = {}\n",
    "gdalInfo = {}\n",
    "\n",
    "useful = {}\n",
    "for k in urlkeys:\n",
    "    gdalInfoReq[k] = \" \".join([\"gdalinfo\", \"-json\", fileFullName[k]])\n",
    "    # print(gdalInfoReq[k])\n",
    "    result = subprocess.run([gdalInfoReq[k]], shell=True, capture_output=True, text=True)\n",
    "    gdalInfo[k] = json.loads(result.stdout)\n",
    "    # if k == 'AEZ_classes':\n",
    "    #     print(json.dumps(gdalInfo[k], indent=2, sort_keys=True))\n",
    "\n",
    "    useful[k] = pull_useful(gdalInfo[k])\n",
    "    print('\\n', k)\n",
    "    print(json.dumps(useful[k], indent=2, sort_keys=True))\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17b9277",
   "metadata": {},
   "source": [
    "<span style=color:blue>Function to pull value from a pixel.  (Thanks to Claudio Spiess)   </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "94e7f8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  state_name county_name        lon        lat\n",
      "0   ILLINOIS      BUREAU -89.534118  41.401629\n",
      "-89.5341179 41.4016294 <class 'numpy.float64'> <class 'numpy.float64'>\n",
      "\n",
      "<class 'numpy.uint8'>\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "\n",
    "def get_coordinate_pixel(tiff_file, lon, lat):\n",
    "    dataset = rasterio.open(tiff_file)\n",
    "    py, px = dataset.index(lon, lat)\n",
    "    # create 1x1px window of the pixel\n",
    "    window = rasterio.windows.Window(px - 1 // 2, py - 1 // 2, 1, 1)\n",
    "    # print(px, px - 1, px - 1 // 2, py, py - 1, py - 1 // 2)\n",
    "    # read rgb values of the window\n",
    "    clip = dataset.read(window=window)\n",
    "    # print(clip)\n",
    "    return clip[0][0][0]\n",
    "\n",
    "# testing the function\n",
    "tiff_file = fileFullName['AEZ_classes']\n",
    "# tiff_file = '/Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__AEZ_classes.tif'\n",
    "print(df_scll.iloc[[0]])\n",
    "test_lon = df_scll.iloc[0]['lon']\n",
    "test_lat = df_scll.iloc[0]['lat']\n",
    "print(test_lon, test_lat, type(test_lon), type(test_lat))\n",
    "print()\n",
    "\n",
    "val = get_coordinate_pixel(tiff_file, test_lon, test_lat)\n",
    "print(type(val))\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7315a36",
   "metadata": {},
   "source": [
    "## <span style=color:blue>Now adding all 5 soil values to the rows of df_scll.  This takes a while to run. </span>\n",
    "\n",
    "<span style=color:blue>With the rasterio function, the retrieved values are of type int.  If using the gdalinfo-based fucntion, then the values coming from the XML are all strings, one should convert to int when loading into the new df that we are building</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3bca4e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  state_name county_name        lon        lat\n",
      "0   ILLINOIS      BUREAU -89.534118  41.401629\n",
      "1   ILLINOIS     CARROLL -89.955679  42.064735\n",
      "2   ILLINOIS       HENRY -90.117744  41.341855\n",
      "3   ILLINOIS  JO DAVIESS -90.174374  42.350666\n",
      "4   ILLINOIS         LEE -89.286030  41.747311\n",
      "559\n",
      "\n",
      "  state_name county_name        lon        lat  AEZ_classes  nutr_ret_high  \\\n",
      "0   ILLINOIS      BUREAU -89.534118  41.401629           17             10   \n",
      "1   ILLINOIS     CARROLL -89.955679  42.064735           17             10   \n",
      "2   ILLINOIS       HENRY -90.117744  41.341855           17             10   \n",
      "3   ILLINOIS  JO DAVIESS -90.174374  42.350666           17             10   \n",
      "4   ILLINOIS         LEE -89.286030  41.747311           17             10   \n",
      "\n",
      "   soil_qual_high  soil_qual_low  suit_irrig_high_soy  \n",
      "0              10              8                10000  \n",
      "1              10             10                10000  \n",
      "2              10              8                10000  \n",
      "3               8              8                10000  \n",
      "4              10              8                10000  \n",
      "559\n"
     ]
    }
   ],
   "source": [
    "df3 = df_scll.copy()\n",
    "print(df3.head())\n",
    "print(len(df3))\n",
    "\n",
    "for k in urlkeys:\n",
    "#     df3[k] = df3.apply(lambda r: fetch_tif_value(r['lon'], r['lat'], k, False), axis=1)\n",
    "    tiff_file = fileFullName[k]\n",
    "    df3[k] = df3.apply(lambda r: get_coordinate_pixel(tiff_file, r['lon'], r['lat']), axis=1)\n",
    "    \n",
    "print()\n",
    "print(df3.head())\n",
    "print(len(df3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c960e3",
   "metadata": {},
   "source": [
    "<span style=color:blue>Looking at full set of values for each of the soil attributes.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1a68f6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AEZ_classes\n",
      "\n",
      "     AEZ_classes\n",
      "0             17\n",
      "9             20\n",
      "13            32\n",
      "16            28\n",
      "37            27\n",
      "89            18\n",
      "393           16\n",
      "396           19\n",
      "449           33\n",
      "494           21\n",
      "\n",
      "nutr_ret_high\n",
      "\n",
      "     nutr_ret_high\n",
      "0               10\n",
      "164              9\n",
      "171              8\n",
      "\n",
      "soil_qual_high\n",
      "\n",
      "     soil_qual_high\n",
      "0                10\n",
      "3                 8\n",
      "50                9\n",
      "81                6\n",
      "87                5\n",
      "151               7\n",
      "175               4\n",
      "\n",
      "soil_qual_low\n",
      "\n",
      "     soil_qual_low\n",
      "0                8\n",
      "1               10\n",
      "6                9\n",
      "16               7\n",
      "50               6\n",
      "87               5\n",
      "385              4\n",
      "\n",
      "suit_irrig_high_soy\n",
      "\n",
      "     suit_irrig_high_soy\n",
      "0                  10000\n",
      "13                    -1\n",
      "103                 9034\n",
      "106                 9173\n",
      "108                 9089\n",
      "109                 8890\n",
      "164                 8329\n",
      "168                 7907\n",
      "171                 7778\n",
      "174                 7797\n",
      "175                 7834\n",
      "179                 8145\n",
      "185                 8650\n",
      "339                    0\n",
      "367                 7832\n",
      "385                 8222\n",
      "387                 9333\n",
      "388                 9353\n",
      "393                 8092\n",
      "394                 8031\n",
      "395                 7785\n",
      "397                 8106\n",
      "401                 8044\n",
      "428                 8688\n",
      "444                 7922\n",
      "445                 7983\n",
      "451                 8010\n",
      "452                 7888\n",
      "526                 9241\n"
     ]
    }
   ],
   "source": [
    "for k in urlkeys:\n",
    "    print()\n",
    "    print(k)\n",
    "    print()\n",
    "    print(df3[[k]].drop_duplicates().head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05679e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "172b7eb6",
   "metadata": {},
   "source": [
    "## <span style=color:blue>Replacing the columns for 'AEZ_classes', 'soil_qual_high', 'soil_qual_low' with multiple \"1-hot\" columns.   (We could also use the OneHotEncoder from scikit, but I'm choosing to do it here and now on the raw data.)</span>\n",
    "\n",
    "<span style=color:blue>Following https://stackoverflow.com/questions/37292872/how-can-i-one-hot-encode-in-python</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "00f4d2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559\n",
      "  state_name county_name        lon        lat  nutr_ret_high  soil_qual_high  \\\n",
      "0   ILLINOIS      BUREAU -89.534118  41.401629             10              10   \n",
      "1   ILLINOIS     CARROLL -89.955679  42.064735             10              10   \n",
      "2   ILLINOIS       HENRY -90.117744  41.341855             10              10   \n",
      "3   ILLINOIS  JO DAVIESS -90.174374  42.350666             10               8   \n",
      "4   ILLINOIS         LEE -89.286030  41.747311             10              10   \n",
      "\n",
      "   soil_qual_low  suit_irrig_high_soy  16  17  18  19  20  21  27  28  32  \n",
      "0              8                10000   0   1   0   0   0   0   0   0   0  \n",
      "1              9                10000   0   1   0   0   0   0   0   0   0  \n",
      "2              8                10000   0   1   0   0   0   0   0   0   0  \n",
      "3              8                 9709   0   1   0   0   0   0   0   0   0  \n",
      "4              8                10000   0   1   0   0   0   0   0   0   0  \n",
      "['state_name', 'county_name', 'lon', 'lat', 'nutr_ret_high', 'soil_qual_high', 'soil_qual_low', 'suit_irrig_high_soy', 16, 17, 18, 19, 20, 21, 27, 28, 32]\n",
      "\n",
      "['state_name', 'county_name', 'lon', 'lat', 'nutr_ret_high', 'soil_qual_high', 'soil_qual_low', 'suit_irrig_high_soy', 'AEZ_1', 'AEZ_2', 'AEZ_3', 'AEZ_4', 'AEZ_5', 'AEZ_6', 'AEZ_7', 'AEZ_8', 'AEZ_9']\n",
      "  state_name county_name        lon        lat  nutr_ret_high  soil_qual_high  \\\n",
      "0   ILLINOIS      BUREAU -89.534118  41.401629             10              10   \n",
      "1   ILLINOIS     CARROLL -89.955679  42.064735             10              10   \n",
      "2   ILLINOIS       HENRY -90.117744  41.341855             10              10   \n",
      "3   ILLINOIS  JO DAVIESS -90.174374  42.350666             10               8   \n",
      "4   ILLINOIS         LEE -89.286030  41.747311             10              10   \n",
      "\n",
      "   soil_qual_low  suit_irrig_high_soy  AEZ_1  AEZ_2  AEZ_3  AEZ_4  AEZ_5  \\\n",
      "0              8                10000      0      1      0      0      0   \n",
      "1              9                10000      0      1      0      0      0   \n",
      "2              8                10000      0      1      0      0      0   \n",
      "3              8                 9709      0      1      0      0      0   \n",
      "4              8                10000      0      1      0      0      0   \n",
      "\n",
      "   AEZ_6  AEZ_7  AEZ_8  AEZ_9  \n",
      "0      0      0      0      0  \n",
      "1      0      0      0      0  \n",
      "2      0      0      0      0  \n",
      "3      0      0      0      0  \n",
      "4      0      0      0      0  \n"
     ]
    }
   ],
   "source": [
    "df4 = df3.copy()\n",
    "\n",
    "# Get one hot encoding of columns 'AEZ-classes'\n",
    "one_hot = pd.get_dummies(df4['AEZ_classes'])\n",
    "# Drop original as it is now encoded\n",
    "df4 = df4.drop('AEZ_classes',axis = 1)\n",
    "# Join the encoded df\n",
    "df4 = df4.join(one_hot)\n",
    "\n",
    "print(len(df4))\n",
    "print(df4.head())\n",
    "print(df4.columns.tolist())\n",
    "# output was ['state_name', 'county_name', 'lon', 'lat', 'nutr_ret_high', \n",
    "#             'soil_qual_high', 'soil_qual_low', 'suit_irrig_high_soy', \n",
    "#              16, 17, 18, 19, 20, 21, 27, 28, 32]\n",
    "\n",
    "print()\n",
    "cols = { 16: 'AEZ_1',\n",
    "         17: 'AEZ_2',\n",
    "         18: 'AEZ_3',\n",
    "         19: 'AEZ_4',\n",
    "         20: 'AEZ_5',\n",
    "         21: 'AEZ_6',\n",
    "         27: 'AEZ_7',\n",
    "         28: 'AEZ_8',\n",
    "         32: 'AEZ_9'}\n",
    "df4 = df4.rename(columns=cols)\n",
    "print(df4.columns.tolist())\n",
    "print(df4.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "10d1d85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559\n",
      "  state_name county_name        lon        lat  nutr_ret_high  soil_qual_low  \\\n",
      "0   ILLINOIS      BUREAU -89.534118  41.401629             10              8   \n",
      "1   ILLINOIS     CARROLL -89.955679  42.064735             10              9   \n",
      "2   ILLINOIS       HENRY -90.117744  41.341855             10              8   \n",
      "3   ILLINOIS  JO DAVIESS -90.174374  42.350666             10              8   \n",
      "4   ILLINOIS         LEE -89.286030  41.747311             10              8   \n",
      "\n",
      "   suit_irrig_high_soy  AEZ_1  AEZ_2  AEZ_3  ...  AEZ_7  AEZ_8  AEZ_9  4  5  \\\n",
      "0                10000      0      1      0  ...      0      0      0  0  0   \n",
      "1                10000      0      1      0  ...      0      0      0  0  0   \n",
      "2                10000      0      1      0  ...      0      0      0  0  0   \n",
      "3                 9709      0      1      0  ...      0      0      0  0  0   \n",
      "4                10000      0      1      0  ...      0      0      0  0  0   \n",
      "\n",
      "   6  7  8  9  10  \n",
      "0  0  0  0  0   1  \n",
      "1  0  0  0  0   1  \n",
      "2  0  0  0  0   1  \n",
      "3  0  0  1  0   0  \n",
      "4  0  0  0  0   1  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "['state_name', 'county_name', 'lon', 'lat', 'nutr_ret_high', 'soil_qual_low', 'suit_irrig_high_soy', 'AEZ_1', 'AEZ_2', 'AEZ_3', 'AEZ_4', 'AEZ_5', 'AEZ_6', 'AEZ_7', 'AEZ_8', 'AEZ_9', 4, 5, 6, 7, 8, 9, 10]\n",
      "\n",
      "['state_name', 'county_name', 'lon', 'lat', 'nutr_ret_high', 'soil_qual_low', 'suit_irrig_high_soy', 'AEZ_1', 'AEZ_2', 'AEZ_3', 'AEZ_4', 'AEZ_5', 'AEZ_6', 'AEZ_7', 'AEZ_8', 'AEZ_9', 'SQH_1', 'SQH_2', 'SQH_3', 'SQH_4', 'SQH_5', 'SQH_6', 'SQH_7']\n",
      "  state_name county_name        lon        lat  nutr_ret_high  soil_qual_low  \\\n",
      "0   ILLINOIS      BUREAU -89.534118  41.401629             10              8   \n",
      "1   ILLINOIS     CARROLL -89.955679  42.064735             10              9   \n",
      "2   ILLINOIS       HENRY -90.117744  41.341855             10              8   \n",
      "3   ILLINOIS  JO DAVIESS -90.174374  42.350666             10              8   \n",
      "4   ILLINOIS         LEE -89.286030  41.747311             10              8   \n",
      "\n",
      "   suit_irrig_high_soy  AEZ_1  AEZ_2  AEZ_3  ...  AEZ_7  AEZ_8  AEZ_9  SQH_1  \\\n",
      "0                10000      0      1      0  ...      0      0      0      0   \n",
      "1                10000      0      1      0  ...      0      0      0      0   \n",
      "2                10000      0      1      0  ...      0      0      0      0   \n",
      "3                 9709      0      1      0  ...      0      0      0      0   \n",
      "4                10000      0      1      0  ...      0      0      0      0   \n",
      "\n",
      "   SQH_2  SQH_3  SQH_4  SQH_5  SQH_6  SQH_7  \n",
      "0      0      0      0      0      0      1  \n",
      "1      0      0      0      0      0      1  \n",
      "2      0      0      0      0      0      1  \n",
      "3      0      0      0      1      0      0  \n",
      "4      0      0      0      0      0      1  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# making a copy of df4, because may run this cell a couple of times as I develop it\n",
    "df5 = df4.copy()\n",
    "\n",
    "# Get one hot encoding of columns 'soil_qual_high'\n",
    "one_hot1 = pd.get_dummies(df5['soil_qual_high'])\n",
    "# Drop original as it is now encoded\n",
    "df5 = df5.drop('soil_qual_high',axis = 1)\n",
    "# Join the encoded df\n",
    "df5 = df5.join(one_hot1)\n",
    "\n",
    "print(len(df5))\n",
    "print(df5.head())\n",
    "print(df5.columns.tolist())\n",
    "# output was ['state_name', 'county_name', 'lon', 'lat', 'nutr_ret_high', \n",
    "#             'soil_qual_low', 'suit_irrig_high_soy', 'AEZ_1', 'AEZ_2', 'AEZ_3', \n",
    "#             'AEZ_4', 'AEZ_5', 'AEZ_6', 'AEZ_7', 'AEZ_8', 'AEZ_9', \n",
    "#             4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "print()\n",
    "cols = { 4: 'SQH_1',\n",
    "         5: 'SQH_2',\n",
    "         6: 'SQH_3',\n",
    "         7: 'SQH_4',\n",
    "         8: 'SQH_5',\n",
    "         9: 'SQH_6',\n",
    "         10: 'SQH_7'}\n",
    "df5 = df5.rename(columns=cols)\n",
    "print(df5.columns.tolist())\n",
    "print(df5.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f02da3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559\n",
      "  state_name county_name        lon        lat  nutr_ret_high  \\\n",
      "0   ILLINOIS      BUREAU -89.534118  41.401629             10   \n",
      "1   ILLINOIS     CARROLL -89.955679  42.064735             10   \n",
      "2   ILLINOIS       HENRY -90.117744  41.341855             10   \n",
      "3   ILLINOIS  JO DAVIESS -90.174374  42.350666             10   \n",
      "4   ILLINOIS         LEE -89.286030  41.747311             10   \n",
      "\n",
      "   suit_irrig_high_soy  AEZ_1  AEZ_2  AEZ_3  AEZ_4  ...  SQH_5  SQH_6  SQH_7  \\\n",
      "0                10000      0      1      0      0  ...      0      0      1   \n",
      "1                10000      0      1      0      0  ...      0      0      1   \n",
      "2                10000      0      1      0      0  ...      0      0      1   \n",
      "3                 9709      0      1      0      0  ...      1      0      0   \n",
      "4                10000      0      1      0      0  ...      0      0      1   \n",
      "\n",
      "   4  5  6  7  8  9  10  \n",
      "0  0  0  0  0  1  0   0  \n",
      "1  0  0  0  0  0  1   0  \n",
      "2  0  0  0  0  1  0   0  \n",
      "3  0  0  0  0  1  0   0  \n",
      "4  0  0  0  0  1  0   0  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "['state_name', 'county_name', 'lon', 'lat', 'nutr_ret_high', 'suit_irrig_high_soy', 'AEZ_1', 'AEZ_2', 'AEZ_3', 'AEZ_4', 'AEZ_5', 'AEZ_6', 'AEZ_7', 'AEZ_8', 'AEZ_9', 'SQH_1', 'SQH_2', 'SQH_3', 'SQH_4', 'SQH_5', 'SQH_6', 'SQH_7', 4, 5, 6, 7, 8, 9, 10]\n",
      "\n",
      "['state_name', 'county_name', 'lon', 'lat', 'nutr_ret_high', 'suit_irrig_high_soy', 'AEZ_1', 'AEZ_2', 'AEZ_3', 'AEZ_4', 'AEZ_5', 'AEZ_6', 'AEZ_7', 'AEZ_8', 'AEZ_9', 'SQH_1', 'SQH_2', 'SQH_3', 'SQH_4', 'SQH_5', 'SQH_6', 'SQH_7', 'SQL_1', 'SQL_2', 'SQL_3', 'SQL_4', 'SQL_5', 'SQL_6', 'SQL_7']\n",
      "  state_name county_name        lon        lat  nutr_ret_high  \\\n",
      "0   ILLINOIS      BUREAU -89.534118  41.401629             10   \n",
      "1   ILLINOIS     CARROLL -89.955679  42.064735             10   \n",
      "2   ILLINOIS       HENRY -90.117744  41.341855             10   \n",
      "3   ILLINOIS  JO DAVIESS -90.174374  42.350666             10   \n",
      "4   ILLINOIS         LEE -89.286030  41.747311             10   \n",
      "\n",
      "   suit_irrig_high_soy  AEZ_1  AEZ_2  AEZ_3  AEZ_4  ...  SQH_5  SQH_6  SQH_7  \\\n",
      "0                10000      0      1      0      0  ...      0      0      1   \n",
      "1                10000      0      1      0      0  ...      0      0      1   \n",
      "2                10000      0      1      0      0  ...      0      0      1   \n",
      "3                 9709      0      1      0      0  ...      1      0      0   \n",
      "4                10000      0      1      0      0  ...      0      0      1   \n",
      "\n",
      "   SQL_1  SQL_2  SQL_3  SQL_4  SQL_5  SQL_6  SQL_7  \n",
      "0      0      0      0      0      1      0      0  \n",
      "1      0      0      0      0      0      1      0  \n",
      "2      0      0      0      0      1      0      0  \n",
      "3      0      0      0      0      1      0      0  \n",
      "4      0      0      0      0      1      0      0  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# making a copy of df5, because may run this cell a couple of times as I develop it\n",
    "df6 = df5.copy()\n",
    "\n",
    "# Get one hot encoding of columns 'soil_qual_low'\n",
    "one_hot2 = pd.get_dummies(df6['soil_qual_low'])\n",
    "# Drop original as it is now encoded\n",
    "df6 = df6.drop('soil_qual_low',axis = 1)\n",
    "# Join the encoded df\n",
    "df6 = df6.join(one_hot2)\n",
    "\n",
    "print(len(df6))\n",
    "print(df6.head())\n",
    "print(df6.columns.tolist())\n",
    "# output was ['state_name', 'county_name', 'lon', 'lat', 'nutr_ret_high', \n",
    "#             'suit_irrig_high_soy', 'AEZ_1', 'AEZ_2', 'AEZ_3', 'AEZ_4', \n",
    "#             'AEZ_5', 'AEZ_6', 'AEZ_7', 'AEZ_8', 'AEZ_9', \n",
    "#             'SQH_1', 'SQH_2', 'SQH_3', 'SQH_4', 'SQH_5', 'SQH_6', 'SQH_7', \n",
    "#              4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "print()\n",
    "cols = { 4: 'SQL_1',\n",
    "         5: 'SQL_2',\n",
    "         6: 'SQL_3',\n",
    "         7: 'SQL_4',\n",
    "         8: 'SQL_5',\n",
    "         9: 'SQL_6',\n",
    "         10: 'SQL_7'}\n",
    "df6 = df6.rename(columns=cols)\n",
    "print(df6.columns.tolist())\n",
    "print(df6.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae805ca",
   "metadata": {},
   "source": [
    "<span style=color:blue>Archiving this df     </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0fdb5fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote file:  /Users/rick/AG-CODE--v03/ML-ARCHIVES--v01/state_county_lon_lat_soil.csv\n"
     ]
    }
   ],
   "source": [
    "archives_dir = '/Users/rick/AG-CODE--v03/ML-ARCHIVES--v01/'\n",
    "filename = 'state_county_lon_lat_soil.csv'\n",
    "df6.to_csv(archives_dir + filename, index=False)\n",
    "print('wrote file: ', archives_dir + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38895b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c3b7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb205d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "350ee9e5",
   "metadata": {},
   "source": [
    "### <span style=color:blue>Comparing the pixel value obtained by the rasterio-based function with pixel value obtained by using gdalinfo and then extraction from the XML that is returned   </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c6cc5840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  state_name county_name        lon        lat\n",
      "0   ILLINOIS      BUREAU -89.534118  41.401629\n",
      "-89.5341179 41.4016294 <class 'numpy.float64'> <class 'numpy.float64'>\n",
      "1086 583\n",
      "gdallocationinfo -xml /Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__AEZ_classes.tif 1086 583\n",
      "<Report pixel=\"1086\" line=\"583\">\n",
      "  <BandReport band=\"1\">\n",
      "    <Value>17</Value>\n",
      "  </BandReport>\n",
      "</Report>\n",
      "\n",
      "\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# converting from lat/long into a pixel location for a global tif with size 4320x2160\n",
    "def convert_to_pix(lon, lat):\n",
    "    x = round((lon + 180) * 12)\n",
    "    y = round((90 - lat) * 12)\n",
    "    return x,y\n",
    "\n",
    "# recall: fullFileName[k] holds full dir + file name for key k\n",
    "f = fileFullName['AEZ_classes']\n",
    "# f = '/Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__AEZ_classes.tif'\n",
    "\n",
    "print(df_scll.iloc[[0]])\n",
    "test_lon = df_scll.iloc[0]['lon']\n",
    "test_lat = df_scll.iloc[0]['lat']\n",
    "print(test_lon, test_lat, type(test_lon), type(test_lat))\n",
    "\n",
    "\n",
    "x,y = convert_to_pix(test_lon, test_lat)\n",
    "\n",
    "print(x,y)\n",
    "\n",
    "# gdal terminal command to fectch pixel value\n",
    "val = \" \".join(['gdallocationinfo -xml', fileFullName['AEZ_classes'], str(x), str(y)])\n",
    "print(val)\n",
    "\n",
    "result = subprocess.run([val], \n",
    "                         shell=True, capture_output=True,text=True)\n",
    "print(result.stdout)\n",
    "print(result.stderr)\n",
    "\n",
    "root = ET.fromstring(result.stdout)\n",
    "val_out = root[0][0].text\n",
    "print(val_out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647be7b6",
   "metadata": {},
   "source": [
    "<span style=color:blue>Now checking the structure of the outputs from each of the 5 .tif files.  Each of them has just 1 band, and so the rasterio-based function above will work</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ecff1b77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AEZ_classes\n",
      "gdallocationinfo -xml /Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__AEZ_classes.tif 1086 583\n",
      "<Report pixel=\"1086\" line=\"583\">\n",
      "  <BandReport band=\"1\">\n",
      "    <Value>17</Value>\n",
      "  </BandReport>\n",
      "</Report>\n",
      "\n",
      "\n",
      "17\n",
      "\n",
      "nutr_ret_high\n",
      "gdallocationinfo -xml /Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__nutr_ret_high.tif 1086 583\n",
      "<Report pixel=\"1086\" line=\"583\">\n",
      "  <BandReport band=\"1\">\n",
      "    <Value>10</Value>\n",
      "  </BandReport>\n",
      "</Report>\n",
      "\n",
      "\n",
      "10\n",
      "\n",
      "soil_qual_high\n",
      "gdallocationinfo -xml /Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__soil_qual_high.tif 1086 583\n",
      "<Report pixel=\"1086\" line=\"583\">\n",
      "  <BandReport band=\"1\">\n",
      "    <Value>10</Value>\n",
      "  </BandReport>\n",
      "</Report>\n",
      "\n",
      "\n",
      "10\n",
      "\n",
      "soil_qual_low\n",
      "gdallocationinfo -xml /Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__soil_qual_low.tif 1086 583\n",
      "<Report pixel=\"1086\" line=\"583\">\n",
      "  <BandReport band=\"1\">\n",
      "    <Value>8</Value>\n",
      "  </BandReport>\n",
      "</Report>\n",
      "\n",
      "\n",
      "8\n",
      "\n",
      "suit_irrig_high_soy\n",
      "gdallocationinfo -xml /Users/rick/AG-CODE--v03/GAEZ-SOIL-for-ML/OUTPUTS/2023-05-20_23-09-36__suit_irrig_high_soy.tif 1086 583\n",
      "<Report pixel=\"1086\" line=\"583\">\n",
      "  <BandReport band=\"1\">\n",
      "    <Value>10000</Value>\n",
      "  </BandReport>\n",
      "</Report>\n",
      "\n",
      "\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# still working with the location of first county -- in df_scll.iloc[[0]]\n",
    "\n",
    "for k in urlkeys:\n",
    "    print()\n",
    "    print(k)\n",
    "    \n",
    "    val = \" \".join(['gdallocationinfo -xml', fileFullName[k], str(x), str(y)])\n",
    "    print(val)\n",
    "\n",
    "    result = subprocess.run([val], \n",
    "                             shell=True, capture_output=True,text=True)\n",
    "    print(result.stdout)\n",
    "    print(result.stderr)\n",
    "\n",
    "    root = ET.fromstring(result.stdout)\n",
    "    val_out = root[0][0].text\n",
    "    print(val_out)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c5a654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pygdal2]",
   "language": "python",
   "name": "conda-env-pygdal2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
