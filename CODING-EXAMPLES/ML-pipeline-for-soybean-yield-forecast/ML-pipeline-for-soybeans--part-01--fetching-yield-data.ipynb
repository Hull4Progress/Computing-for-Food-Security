{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d62abd29",
   "metadata": {},
   "source": [
    "## <span style=color:blue>This notebook is fetching soybean yields for an ML pipeline </spann>\n",
    "\n",
    "<span style=color:blue>It pulls from USDA NASS.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "748db334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This useful if I want to give unique names to directories or files\n",
    "import datetime\n",
    "def curr_timestamp():\n",
    "    current_datetime = datetime.datetime.now()\n",
    "    formatted_datetime = current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    return formatted_datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081bcb69",
   "metadata": {},
   "source": [
    "### <span style=color:blue> Accessing USDA NASS, following code from https://towardsdatascience.com/harvest-and-analyze-agricultural-data-with-the-usda-nass-api-python-and-tableau-a6af374b8138.  In first cell below we define a class for interacting with the NASS QuickStats API, and in second cell we illustrate how to invoke that class </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec026614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://towardsdatascience.com/harvest-and-analyze-agricultural-data-with-the-usda-nass-api-python-and-tableau-a6af374b8138\n",
    "# with edits\n",
    "\n",
    "#   Name:           c_usda_quick_stats.py\n",
    "#   Author:         Randy Runtsch\n",
    "#   Date:           March 29, 2022\n",
    "#   Project:        Query USDA QuickStats API\n",
    "#   Author:         Randall P. Runtsch\n",
    "#\n",
    "#   Description:    Query the USDA QuickStats api_GET API with a specified set of \n",
    "#                   parameters. Write the retrieved data, in CSV format, to a file.\n",
    "#\n",
    "#   See Quick Stats (NASS) API user guide:  https://quickstats.nass.usda.gov/api\n",
    "#   Request a QuickStats API key here:      https://quickstats.nass.usda.gov/api#param_define\n",
    "#\n",
    "#   Attribution: This product uses the NASS API but is not endorsed or certified by NASS.\n",
    "#\n",
    "#   Changes\n",
    "#\n",
    "\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "from requests.utils import requote_uri\n",
    "import requests\n",
    "\n",
    "# One has to get a NASS API key - please get your own\n",
    "my_NASS_API_key = '8932BB3A-66B1-3140-8FCF-9EF701D75C7B'\n",
    "\n",
    "class c_usda_quick_stats:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # Set the USDA QuickStats API key, API base URL, and output file path where CSV files will be written. \n",
    "\n",
    "        # self.api_key = 'PASTE_YOUR_API_KEY_HERE'\n",
    "        self.api_key = my_NASS_API_key\n",
    "\n",
    "        self.base_url_api_get = 'http://quickstats.nass.usda.gov/api/api_GET/?key=' \\\n",
    "                                + self.api_key + '&'\n",
    "\n",
    "    def get_data(self, parameters, file_path, file_name):\n",
    "\n",
    "        # Call the api_GET api with the specified parameters. \n",
    "        # Write the CSV data to the specified output file.\n",
    "\n",
    "        # Create the full URL and retrieve the data from the Quick Stats server.\n",
    "        \n",
    "        full_url = self.base_url_api_get + parameters        \n",
    "        print(full_url)\n",
    "\n",
    "        try:\n",
    "            s_result = urllib.request.urlopen(full_url)\n",
    "            # print(type(s_result))\n",
    "            print(s_result.status, s_result.reason)\n",
    "            # print(s_result.status_code)\n",
    "            s_text = s_result.read().decode('utf-8')\n",
    "\n",
    "            # Create the output file and write the CSV data records to the file.\n",
    "\n",
    "            s_file_name = file_path + file_name\n",
    "            o_file = open(s_file_name, \"w\", encoding=\"utf8\")\n",
    "            o_file.write(s_text)\n",
    "            o_file.close()\n",
    "        except HTTPError as error:\n",
    "            print(error.code, error.reason)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"An error occurred while fetching the data: {e}\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Failed to parse the response data: {e}\")\n",
    "        except:\n",
    "            print(f\"Failed because of unknown exception; perhaps the USDA NASS site is down\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1559bf",
   "metadata": {},
   "source": [
    "<span style=color:blue>First, a test query based on Randall Runtsch...    </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da48f5fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://quickstats.nass.usda.gov/api/api_GET/?key=8932BB3A-66B1-3140-8FCF-9EF701D75C7B&source_desc=SURVEY&sector_desc%3DFARMS%20%26%20LANDS%20%26%20ASSETS&commodity_desc%3DFARM%20OPERATIONS&statisticcat_desc%3DAREA%20OPERATED&unit_desc=ACRES&freq_desc=ANNUAL&reference_period_desc=YEAR&year__GE=1997&agg_level_desc=NATIONAL&state_name%3DUS%20TOTAL&format=CSV\n",
      "200 OK\n"
     ]
    }
   ],
   "source": [
    "# from https://towardsdatascience.com/harvest-and-analyze-agricultural-data-with-the-usda-nass-api-python-and-tableau-a6af374b8138\n",
    "# with edits\n",
    "\n",
    "#   Date:           March 29, 2022\n",
    "#   Project:        Program controller to query USDA QuickStats API\n",
    "#   Author:         Randall P. Runtsch\n",
    "#\n",
    "#   Description:    Create an instance of the c_usda_quick_stats class. Call it with\n",
    "#                   the desired search parameter and output file name.\n",
    "#\n",
    "#   Attribution: This product uses the NASS API but is not endorsed or certified by NASS.\n",
    "#\n",
    "#   Changes\n",
    "#\n",
    "\n",
    "import sys\n",
    "import urllib.parse\n",
    "\n",
    "output_dir = '/Users/rick/AG-CODE--v03/USDA-NASS--v01/OUTPUTS/'\n",
    "\n",
    "# Create a string with search parameters, then create an instance of\n",
    "# the c_usda_quick_stats class and use that to fetch data from QuickStats\n",
    "# and write it to a file\n",
    "\n",
    "\n",
    "\n",
    "# the QuickStats site is very senstivite to how the full URL is built up.\n",
    "# For example, the following spec for the parameters works\n",
    "# But if you replace the line \"'&unit_desc=ACRES' + \\\" with\n",
    "# the line \"'&' + urllib.parse.quote('unit_desc-ACRES')\"\n",
    "# then the site responds saying that you have exceeded the 50,000 record limit for one query\n",
    "\n",
    "parameters =    'source_desc=SURVEY' +  \\\n",
    "                '&' + urllib.parse.quote('sector_desc=FARMS & LANDS & ASSETS') + \\\n",
    "                '&' + urllib.parse.quote('commodity_desc=FARM OPERATIONS') + \\\n",
    "                '&' + urllib.parse.quote('statisticcat_desc=AREA OPERATED') + \\\n",
    "                '&unit_desc=ACRES' + \\\n",
    "                '&freq_desc=ANNUAL' + \\\n",
    "                '&reference_period_desc=YEAR' + \\\n",
    "                '&year__GE=1997' + \\\n",
    "                '&agg_level_desc=NATIONAL' + \\\n",
    "                '&' + urllib.parse.quote('state_name=US TOTAL') + \\\n",
    "                '&format=CSV'\n",
    "\n",
    "stats = c_usda_quick_stats()\n",
    "\n",
    "# Including curr_timestamp() into file name to keep outputs separated during development/exploration\n",
    "s_json = stats.get_data(parameters, output_dir, 'national_farm_survey_acres_ge_1997_' + curr_timestamp() + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194bf18e",
   "metadata": {},
   "source": [
    "<span style=color:blue>Now a query that fetches useful soybean yield data.  I am focused on the top 7 soy-producing states in the US, and on the years 2003 to 2022.   </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6510e506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://quickstats.nass.usda.gov/api/api_GET/?key=8932BB3A-66B1-3140-8FCF-9EF701D75C7B&source_desc=SURVEY&sector_desc=CROPS&group_desc%3DFIELD%20CROPS&commodity_desc=SOYBEANS&statisticcat_desc=YIELD&geographic_level=STATE&agg_level_desc=COUNTY&state_name=ILLINOIS&state_name=IOWA&state_name=MINNESTOTA&state_name=INDIANA&state_name=OHIO&state_name=NEBRASKA&state_name=MISSOURI&year__GE=2003&year__LE=2022&format=CSV\n",
      "200 OK\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import urllib.parse\n",
    "\n",
    "output_dir = '/Users/rick/AG-CODE--v03/USDA-NASS--v01/OUTPUTS/'\n",
    "\n",
    "# Create a string with search parameters, then create an instance of\n",
    "# the c_usda_quick_stats class and use that to fetch data from QuickStats\n",
    "# and write it to a file\n",
    "\n",
    "# It took a while to get the parameter names just right...\n",
    "#   The parameters names are listed in\n",
    "#      https://quickstats.nass.usda.gov/param_define\n",
    "#   (some additional resources in https://quickstats.nass.usda.gov/tutorials)\n",
    "#   Also, look at the column names that show up in the csv files that you get back\n",
    "parameters =    'source_desc=SURVEY' +  \\\n",
    "                '&sector_desc=CROPS' + \\\n",
    "                '&' + urllib.parse.quote('group_desc=FIELD CROPS') + \\\n",
    "                '&commodity_desc=SOYBEANS' + \\\n",
    "                '&statisticcat_desc=YIELD' + \\\n",
    "                '&geographic_level=STATE' + \\\n",
    "                '&agg_level_desc=COUNTY' + \\\n",
    "                '&state_name=ILLINOIS' + \\\n",
    "                '&state_name=IOWA' + \\\n",
    "                '&state_name=MINNESTOTA' + \\\n",
    "                '&state_name=INDIANA' + \\\n",
    "                '&state_name=OHIO' + \\\n",
    "                '&state_name=NEBRASKA' + \\\n",
    "                '&state_name=MISSOURI' + \\\n",
    "                '&year__GE=2003' + \\\n",
    "                '&year__LE=2022' + \\\n",
    "                '&format=CSV'\n",
    "\n",
    "stats = c_usda_quick_stats()\n",
    "\n",
    "# holding this timestamp; we may used it to import the created csv file\n",
    "latest_curr_timestamp = curr_timestamp()\n",
    "filename = 'soybean_yield_data__' + latest_curr_timestamp + '.csv'\n",
    "\n",
    "# Including curr_timestamp() into file name to keep outputs separated during development/exploration\n",
    "stats.get_data(parameters, output_dir, 'soybean_yield_data__' + latest_curr_timestamp + '.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2926f437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c890336",
   "metadata": {},
   "source": [
    "### <span style=color:blue>After inspecting the output we see that there is double counting.  In particular, see the columns for \"short_desc\".  So, we will drop all records with short_desc != \"SOYBEANS - YIELD, MEASURED IN BU / ACRE\"</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dec3aa1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              short_desc\n",
      "0                SOYBEANS - YIELD, MEASURED IN BU / ACRE\n",
      "10295  SOYBEANS, FOLLOWING ANOTHER CROP (DOUBLE CROPP...\n",
      "10349  SOYBEANS, IRRIGATED - YIELD, MEASURED IN BU / ...\n",
      "11232  SOYBEANS, NON-IRRIGATED - YIELD, MEASURED IN B...\n",
      "12068  SOYBEANS, NOT FOLLOWING ANOTHER CROP - YIELD, ...\n",
      "\n",
      "10295\n",
      "\n",
      "9952\n",
      "\n",
      "559\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "output_dir = '/Users/rick/AG-CODE--v03/USDA-NASS--v01/OUTPUTS/'\n",
    "\n",
    "df = pd.read_csv(output_dir + filename)\n",
    "# print(df.head())\n",
    "\n",
    "df1 = df[['short_desc']].drop_duplicates()\n",
    "print(df1.head(10))\n",
    "print()\n",
    "\n",
    "# keep only records about full yield\n",
    "df = df[df['short_desc'] == \"SOYBEANS - YIELD, MEASURED IN BU / ACRE\"]\n",
    "print(len(df))\n",
    "# 10295\n",
    "\n",
    "print()\n",
    "\n",
    "# found some bad_county_names by visual inspection of the csv\n",
    "bad_county_names = ['OTHER COUNTIES', 'OTHER (COMBINED) COUNTIES']\n",
    "df = df[~df.county_name.isin(bad_county_names)]\n",
    "\n",
    "print(len(df))\n",
    "# 9952\n",
    "\n",
    "print()\n",
    "\n",
    "df2 = df[['state_name','county_name']].drop_duplicates()\n",
    "print(len(df2))\n",
    "# 559\n",
    "\n",
    "# Note: using SQL I found that of the 559 state-county pairs total:\n",
    "#          212 state-county pairs have data for all 20 years\n",
    "#          347 state-county pairs have data for < 20 years\n",
    "#\n",
    "#          486 have year 2022\n",
    "#          418 have year 2021\n",
    "#          514 have year 2020\n",
    "# I will live with that\n",
    "\n",
    "# cleaning up a column name\n",
    "df = df.rename(columns={'Value': 'yield'})\n",
    "\n",
    "output_dir = '/Users/rick/AG-CODE--v03/USDA-NASS--v01/OUTPUTS/'\n",
    "output_file = 'repaired_yield__' + curr_timestamp() + '.csv'\n",
    "\n",
    "df.to_csv(output_dir + output_file, index=False)\n",
    "\n",
    "# I imported this table into postgres so that I could use SQL ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0555f187",
   "metadata": {},
   "source": [
    "#### <span style=color:blue>Saving the csv I'm happy with in a designated place in my \"archives\" directory</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "020f70ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/rick/AG-CODE--v03/ML-ARCHIVES--v01/soybean_yield_data.csv'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "output_dir = '/Users/rick/AG-CODE--v03/USDA-NASS--v01/OUTPUTS/'\n",
    "archives_dir = '/Users/rick/AG-CODE--v03/ML-ARCHIVES--v01/'\n",
    "src_file = output_file # from preceding cell\n",
    "tgt_file = 'soybean_yield_data.csv'\n",
    "\n",
    "shutil.copyfile(output_dir + src_file, archives_dir + tgt_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58931598",
   "metadata": {},
   "source": [
    "#### <span style=color:blue>Projecting out the columns and records that I don't need for my ML learning table, and archiving that result, also. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1624c582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year state_name county_name  yield\n",
      "0  2022   ILLINOIS      BUREAU   67.5\n",
      "1  2021   ILLINOIS      BUREAU   66.4\n",
      "2  2020   ILLINOIS      BUREAU   64.8\n",
      "3  2019   ILLINOIS      BUREAU   57.4\n",
      "4  2018   ILLINOIS      BUREAU   68.5\n",
      "\n",
      "9952\n",
      "Empty DataFrame\n",
      "Columns: [year, state_name, county_name, yield]\n",
      "Index: []\n",
      "\n",
      "wrote file  /Users/rick/AG-CODE--v03/ML-ARCHIVES--v01/year_state_county_yield.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "archives_dir = '/Users/rick/AG-CODE--v03/ML-ARCHIVES--v01/'\n",
    "tgt_file = 'soybean_yield_data.csv'\n",
    "\n",
    "df = pd.read_csv(archives_dir + tgt_file)\n",
    "# print(df.head())\n",
    "\n",
    "cols_to_keep = ['year','state_name','county_name','yield']\n",
    "dfml = df[cols_to_keep]\n",
    "\n",
    "print(dfml.head())\n",
    "print()\n",
    "print(dfml.shape[0])\n",
    "# Note: this particular df has 9952 rows\n",
    "\n",
    "# checking there are no null values for 'yield':\n",
    "print(dfml[dfml['yield'].isnull()].head())\n",
    "\n",
    "tgt_file_01 = 'd'\n",
    "dfml.to_csv(archives_dir + tgt_file_01, index=False)\n",
    "print('\\nwrote file ', archives_dir + tgt_file_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1da869f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
